#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
InspareAI - Belge Ä°ÅŸleme ve VektÃ¶r VeritabanÄ± EriÅŸimi.
Bu modÃ¼l, vektÃ¶r veritabanÄ± sorgulama ve belgeleri iÅŸleme fonksiyonlarÄ±nÄ± iÃ§erir.
"""

import re
import numpy as np
from datetime import datetime
import os
import concurrent.futures
from typing import List, Dict, Any

# Hata durumunda vector modÃ¼lÃ¼nÃ¼ gÃ¼venli ÅŸekilde import et
try:
    from vector import retriever, vectorstore
    VECTOR_DB_AVAILABLE = True
except ImportError as e:
    print(f"UYARI: vector.py dosyasÄ± bulunamadÄ± veya iÃ§e aktarÄ±lamadÄ±: {str(e)}")
    VECTOR_DB_AVAILABLE = False
    retriever = None
    vectorstore = None
except Exception as e:
    print(f"UYARI: VektÃ¶r veritabanÄ± yÃ¼klenirken hata oluÅŸtu: {str(e)}")
    VECTOR_DB_AVAILABLE = False
    retriever = None
    vectorstore = None

from inspareai.config.constants import (MAX_DOCUMENTS, MAX_DOCS_PER_SPEAKER, 
                                      OTHER_DOCS_LIMIT, CONTENT_MAX_LENGTH, 
                                      FILENAME_MAX_LENGTH, CHRONO_KEYWORDS, 
                                      COMPARISON_KEYWORDS)
from inspareai.utils.text import calculate_relevance, extract_keywords


def retrieve_relevant_documents(question, keywords=None):
    """
    Sorguyla ilgili dokÃ¼manlarÄ± vektÃ¶r veritabanÄ±ndan getirir.
    
    Args:
        question (str): KullanÄ±cÄ± sorusu
        keywords (list, optional): Ã–nceden Ã§Ä±karÄ±lmÄ±ÅŸ anahtar kelimeler
        
    Returns:
        list: Ä°lgili belgelerin listesi
    """
    if not VECTOR_DB_AVAILABLE or retriever is None:
        raise ValueError("VektÃ¶r veritabanÄ± kullanÄ±lamÄ±yor.")
    
    if keywords is None:
        keywords = extract_keywords(question)
        
    try:
        # Retriever'Ä± optimize et
        if hasattr(retriever, 'search_kwargs'):
            if retriever.search_kwargs.get("search_type", None) != "mmr":
                # MMR'yi etkinleÅŸtir - Ã§eÅŸitliliÄŸi artÄ±rÄ±r
                retriever.search_kwargs["search_type"] = "mmr"
                retriever.search_kwargs["fetch_k"] = max(retriever.search_kwargs.get("fetch_k", 50), 50)
                retriever.search_kwargs["lambda_mult"] = 0.8  # Alaka-Ã§eÅŸitlilik dengesi
        
        # DokÃ¼manlarÄ± getir
        docs = retriever.invoke(question)
        
        # Optimize edilmiÅŸ sÄ±ralama iÃ§in belgeleri puanlandÄ±r
        docs = score_and_sort_documents(docs, question, keywords)
        
        return docs
    except Exception as e:
        print(f"DokÃ¼man getirilirken hata: {e}")
        raise e


def score_and_sort_documents(docs, question, keywords):
    """
    Belgeleri alakalarÄ±na gÃ¶re puanlandÄ±rÄ±r ve sÄ±ralar.
    
    Args:
        docs (list): Belgeler listesi
        question (str): KullanÄ±cÄ± sorusu
        keywords (list): Anahtar kelimeler
        
    Returns:
        list: SÄ±ralanmÄ±ÅŸ belgeler
    """
    def cosine_similarity(vec1, vec2):
        vec1 = np.array(vec1)
        vec2 = np.array(vec2)
        if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:
            return 0.0
        return float(np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)))
    
    # Paralel puanlama iÃ§in
    if keywords and hasattr(vectorstore, 'embed_query') and hasattr(vectorstore, 'embed_documents'):
        try:
            # Soru ve belge vektÃ¶rlerini oluÅŸtur
            question_emb = vectorstore.embed_query(question)
            doc_texts = [doc.page_content for doc in docs]
            doc_embs = vectorstore.embed_documents(doc_texts)
            
            # Her belge iÃ§in alaka puanÄ±nÄ± hesapla
            for i, doc in enumerate(docs):
                kw_score = calculate_relevance(doc, keywords)
                emb_score = cosine_similarity(question_emb, doc_embs[i])
                emb_score = max(emb_score, 0.0)
                kw_score_norm = min(max(kw_score / 2.0, 0.0), 1.0)
                
                # Puanlama formÃ¼lÃ¼
                doc.final_score = 0.75 * kw_score_norm + 0.25 * emb_score
                
                # KonuÅŸmacÄ± puanlamasÄ±
                if "speaker" in question.lower() and doc.metadata.get("speaker", "").lower() in question.lower():
                    doc.final_score *= 1.5  # KonuÅŸmacÄ± eÅŸleÅŸirse fazladan puan
            
            return sorted(docs, key=lambda d: getattr(d, 'final_score', 0), reverse=True)
        except Exception as e:
            print(f"GeliÅŸmiÅŸ sÄ±ralama uygulanamadÄ±: {e}")
    
    # VarsayÄ±lan sÄ±ralama
    return sorted(docs, key=lambda doc: calculate_relevance(doc, keywords), reverse=True) if keywords else docs


def filter_and_prepare_documents(docs, question):
    """
    Belgeleri filtreler ve sorgu tipine gÃ¶re Ã¶zel hazÄ±rlamalar yapar.
    
    Args:
        docs (list): Belgeler listesi
        question (str): KullanÄ±cÄ± sorusu
        
    Returns:
        list: FiltrelenmiÅŸ belgeler
    """
    # Ä°lk MAX_DOCUMENTS belgeyi al
    filtered_docs = docs[:MAX_DOCUMENTS]
    
    # Sorgu tipini algÄ±lama
    is_chronological = any(word in question.lower() for word in CHRONO_KEYWORDS)
    is_speaker_specific = "speaker" in question.lower() or "konuÅŸmacÄ±" in question.lower()
    is_comparison = any(word in question.lower() for word in COMPARISON_KEYWORDS)
    
    # Kronolojik analiz iÃ§in belgeleri sÄ±rala
    if is_chronological:
        filtered_docs = sort_documents_chronologically(filtered_docs)
    
    # KonuÅŸmacÄ± spesifik analiz
    if is_speaker_specific:
        speaker_matches = []
        for speaker_letter in "ABCDEFGHIJKLMNOPQRSTUVWXYZ":
            if f"speaker {speaker_letter.lower()}" in question.lower() or f"speaker {speaker_letter}" in question.lower():
                speaker_matches.append(speaker_letter)
        
        if speaker_matches:
            # Ä°lgili konuÅŸmacÄ±larÄ±n belgelerini baÅŸa al
            speaker_docs = [doc for doc in filtered_docs if doc.metadata.get("speaker", "").upper() in speaker_matches]
            other_docs = [doc for doc in filtered_docs if doc.metadata.get("speaker", "").upper() not in speaker_matches]
            filtered_docs = speaker_docs + other_docs[:max(OTHER_DOCS_LIMIT, MAX_DOCUMENTS-len(speaker_docs))]
    
    # KarÅŸÄ±laÅŸtÄ±rma analizi iÃ§in belge Ã§eÅŸitliliÄŸi
    if is_comparison:
        # FarklÄ± konuÅŸmacÄ±lardan belgeleri dengeli ÅŸekilde dahil et
        speaker_groups = {}
        for doc in filtered_docs:
            speaker = doc.metadata.get("speaker", "Unknown")
            if speaker not in speaker_groups:
                speaker_groups[speaker] = []
            speaker_groups[speaker].append(doc)
        
        # Her konuÅŸmacÄ±dan dengeli sayÄ±da belge seÃ§
        balanced_docs = []
        max_per_speaker = MAX_DOCS_PER_SPEAKER
        
        # En alakalÄ± konuÅŸmacÄ±larÄ± sÄ±rala
        sorted_speakers = sorted(speaker_groups.keys(), key=lambda s: len(speaker_groups[s]), reverse=True)
        
        for speaker in sorted_speakers:
            balanced_docs.extend(speaker_groups[speaker][:max_per_speaker])
        
        filtered_docs = balanced_docs[:MAX_DOCUMENTS]
    
    return filtered_docs


def format_context(docs):
    """
    Belgeleri baÄŸlam olarak formatlar.
    
    Args:
        docs (list): Belgeler listesi
        
    Returns:
        str: FormatlanmÄ±ÅŸ baÄŸlam metni
    """
    context_parts = []
    
    for i, doc in enumerate(docs, 1):
        # Dosya adÄ±nÄ± kÄ±salt
        source = doc.metadata.get('source', 'Bilinmiyor')
        if len(source) > FILENAME_MAX_LENGTH:
            source = source[:FILENAME_MAX_LENGTH-3] + "..."
        
        # Zaman bilgisini doÄŸru ÅŸekilde biÃ§imlendir
        time_info = doc.metadata.get('time', '')
        if not time_info or time_info == "00:00:00 - 00:00:00":
            start_time = doc.metadata.get('start_time', '')
            end_time = doc.metadata.get('end_time', '')
            if start_time and end_time:
                time_info = f"{start_time} - {end_time}"
        
        # Ä°Ã§eriÄŸi temizle ve biÃ§imlendir
        try:
            if not hasattr(doc, 'page_content') or doc.page_content is None:
                content = "Belge iÃ§eriÄŸi alÄ±namadÄ±"
            else:
                content = doc.page_content
                if 'Content: ' in content:
                    content = content.split('Content: ')[-1]
                content = content.strip()
            
            # Ä°Ã§eriÄŸi belirli bir uzunluÄŸa kÄ±salt
            if len(content) > CONTENT_MAX_LENGTH:
                content = content[:CONTENT_MAX_LENGTH-3] + "..."
        except Exception as e:
            print(f"Ä°Ã§erik iÅŸlenirken hata: {e}")
            content = "Belge iÃ§eriÄŸi iÅŸlenirken hata oluÅŸtu"
        
        # Belge parÃ§asÄ±nÄ± biÃ§imlendir
        context_part = f"[Belge {i}]\nDosya: {source}\nZaman: {time_info}\nKonuÅŸmacÄ±: {doc.metadata.get('speaker', 'Bilinmiyor')}\nÄ°Ã§erik: {content}"
        context_parts.append(context_part)
    
    return "\n\n".join(context_parts)


def sort_documents_chronologically(docs):
    """
    Belgeleri kronolojik olarak sÄ±ralar.
    
    Args:
        docs (list): Belgeler listesi
        
    Returns:
        list: Kronolojik olarak sÄ±ralanmÄ±ÅŸ belgeler
    """
    def extract_time(doc):
        """Belgeden zaman bilgisini Ã§Ä±karÄ±r"""
        time_str = doc.metadata.get('time', '')
        
        if not time_str or time_str == "00:00:00 - 00:00:00":
            start_time = doc.metadata.get('start_time', '00:00:00')
            return start_time
        
        # Zaman bilgisini ayrÄ±ÅŸtÄ±r
        match = re.search(r'(\d+:\d+:\d+)', time_str)
        if match:
            return match.group(1)
        return "00:00:00"
    
    # Belgeleri zamanÄ±na gÃ¶re sÄ±rala
    try:
        # Zaman formatÄ±nÄ± dÃ¼zgÃ¼n bir ÅŸekilde ayrÄ±ÅŸtÄ±r
        time_sorted = sorted(docs, key=extract_time)
        return time_sorted
    except Exception as e:
        print(f"Kronolojik sÄ±ralama hatasÄ±: {e}")
        return docs  # Hata durumunda orijinal sÄ±ralama korunur


def format_sources(docs):
    """
    KaynaklarÄ± formatlar.
    
    Args:
        docs (list): Belgeler listesi
        
    Returns:
        str: FormatlanmÄ±ÅŸ kaynak bilgileri
    """
    sources_text = "=== KULLANILAN KAYNAKLAR ===\n"
    
    # KullanÄ±lan dosyalarÄ± toplama ve grupla
    source_groups = {}
    
    # Her bir dokÃ¼manÄ± iÅŸle ve dosyalara gÃ¶re grupla
    for i, doc in enumerate(docs, 1):
        source = doc.metadata.get("source", "Bilinmiyor")
        
        # Zaman bilgisini doÄŸrudan metadata'dan al
        time_info = doc.metadata.get("time", "")
        
        # EÄŸer time bilgisi yoksa veya varsayÄ±lan deÄŸerse, start_time ve end_time'Ä± kontrol et
        if not time_info or time_info == "Bilinmiyor" or time_info == "00:00:00 - 00:00:00":
            start_time = doc.metadata.get("start_time", "")
            end_time = doc.metadata.get("end_time", "")
            if start_time and end_time:
                # VarsayÄ±lan deÄŸerleri kontrol et
                if start_time != "00:00:00" or end_time != "00:00:00":
                    time_info = f"{start_time} - {end_time}"
                else:
                    # Ä°Ã§erikte zaman bilgisi var mÄ± kontrol et
                    content = doc.page_content
                    time_match = re.search(r"Time:\s*(\d+:\d+:\d+\s*-\s*\d+:\d+:\d+)", content)
                    if time_match:
                        time_info = time_match.group(1)
                    else:
                        time_info = "Zaman bilgisi yok"
            else:
                time_info = "Zaman bilgisi yok"
        
        # KonuÅŸmacÄ± bilgisini al
        speaker = doc.metadata.get("speaker", "Bilinmiyor")
        if speaker == "Bilinmiyor":
            # Ä°Ã§erikte konuÅŸmacÄ± bilgisi var mÄ± kontrol et
            content = doc.page_content
            speaker_match = re.search(r"Speaker:\s*([A-Za-z0-9]+)", content)
            if speaker_match:
                speaker = speaker_match.group(1)
        
        # Ä°Ã§erik Ã¶rneÄŸi (ilk 50 karakter)
        content = doc.page_content.split('Content: ')[-1] if 'Content: ' in doc.page_content else doc.page_content
        content_preview = content[:50] + "..." if len(content) > 50 else content
        
        # Dosya bazlÄ± gruplama
        if source not in source_groups:
            source_groups[source] = []
        
        source_groups[source].append({
            "index": i,
            "time": time_info,
            "speaker": speaker,
            "content_preview": content_preview.replace("\n", " ")
        })
    
    # GruplarÄ± formatlayarak gÃ¶ster
    for source_name, entries in source_groups.items():
        # Dosya baÅŸlÄ±ÄŸÄ±nÄ± gÃ¶ster
        sources_text += f"\nğŸ“„ {source_name} ({len(entries)} parÃ§a):\n"
        
        # Her bir parÃ§ayÄ± listele
        for entry in entries:
            sources_text += f"  {entry['index']}. Zaman: {entry['time']}, KonuÅŸmacÄ±: {entry['speaker']}\n"
        
        sources_text += "\n"
    
    # Toplam istatistik ekle
    sources_text += f"\nToplam {len(docs)} transkript parÃ§asÄ± kullanÄ±ldÄ±, {len(source_groups)} farklÄ± dosyadan."
    
    return sources_text


def save_analysis(question, result):
    """
    Analiz sonucunu kaydeder.
    
    Args:
        question (str): KullanÄ±cÄ± sorusu
        result (str): Analiz sonucu
        
    Returns:
        str: Kaydedilen dosyanÄ±n adÄ±
    """
    # Kaydedilecek klasÃ¶rÃ¼ oluÅŸtur
    save_dir = "analysis_results"
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    
    # Dosya adÄ±nÄ± oluÅŸtur
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_question = "".join(c if c.isalnum() else "_" for c in question[:30])
    filename = f"{save_dir}/analiz_{timestamp}_{safe_question}.txt"
    
    # DosyayÄ± oluÅŸtur ve analizi kaydet
    with open(filename, "w", encoding="utf-8") as f:
        f.write(f"Soru: {question}\n\n")
        f.write(f"Analiz ZamanÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("="*50 + "\n\n")
        f.write(result)
    
    print(f"Analiz sonucu kaydedildi: {filename}")
    return filename
