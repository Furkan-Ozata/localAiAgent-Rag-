from langchain_ollama import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from utils.streaming import stream_llm_response, create_academic_formatted_stream
import os
import time
import json
import hashlib
from datetime import datetime
from collections import defaultdict
import concurrent.futures
import re
import subprocess
import numpy as np
import traceback

# ========== SABITLER ==========
# Maksimum dÃ¶kÃ¼man sayÄ±sÄ± ve filtreleme limitleri
MAX_DOCUMENTS = 70  # Ä°ÅŸlenecek maksimum dÃ¶kÃ¼man sayÄ±sÄ±
MAX_DOCS_PER_SPEAKER = 15  # KonuÅŸmacÄ± baÅŸÄ±na maksimum dÃ¶kÃ¼man sayÄ±sÄ±
OTHER_DOCS_LIMIT = 35  # KonuÅŸmacÄ±ya Ã¶zel olmayan maksimum dÃ¶kÃ¼man sayÄ±sÄ±

# Ä°Ã§erik sÄ±nÄ±rlamalarÄ±
CONTENT_MAX_LENGTH = 1000  # Belge iÃ§eriÄŸi maksimum karakter sayÄ±sÄ±
CONTEXT_TRUNCATION = 4000  # BaÄŸlam kesme limiti
FALLBACK_CONTEXT_LIMIT = 2000  # Yedek yÃ¶ntem maksimum baÄŸlam limiti
EMERGENCY_CONTEXT_LIMIT = 1000  # Acil durum maksimum baÄŸlam limiti
FILENAME_MAX_LENGTH = 40  # Dosya adÄ± maksimum karakter sayÄ±sÄ±
MIN_RESPONSE_LENGTH = 20  # Minimum LLM yanÄ±t uzunluÄŸu

# Zaman aÅŸÄ±mÄ± deÄŸerleri
PRIMARY_TIMEOUT = 30  # Ä°lk LLM yanÄ±t zaman aÅŸÄ±mÄ± (saniye)
SECONDARY_TIMEOUT = 30  # Ä°kincil LLM yanÄ±t zaman aÅŸÄ±mÄ± (saniye)
EMERGENCY_TIMEOUT = 15  # Acil durum LLM yanÄ±t zaman aÅŸÄ±mÄ± (saniye)

# Ã–nbellek parametreleri
CACHE_CLEAN_THRESHOLD = 100  # Bellek Ã¶nbelleÄŸi temizleme eÅŸiÄŸi
CACHE_KEEP_COUNT = 50  # Bellek Ã¶nbelleÄŸinde tutulacak Ã¶ÄŸe sayÄ±sÄ±
DISK_CACHE_SAVE_INTERVAL = 5  # Ã–nbelleÄŸin diske kaydedilme sÄ±klÄ±ÄŸÄ±

# Kronolojik analiz anahtar kelimeleri
CHRONO_KEYWORDS = ["kronoloji", "zaman", "sÄ±ra", "geliÅŸme", "tarihsel", "sÃ¼reÃ§"]

# KarÅŸÄ±laÅŸtÄ±rma analizi anahtar kelimeleri
COMPARISON_KEYWORDS = ["karÅŸÄ±laÅŸtÄ±r", "fark", "benzerlik", "benzer", "farklÄ±"]

# TurkishStemmer iÃ§in gÃ¼venli import
try:
    from TurkishStemmer import TurkishStemmer
    stemmer = TurkishStemmer()
    STEMMER_AVAILABLE = True
    print("TurkishStemmer baÅŸarÄ±yla yÃ¼klendi.")
    print("Program Ã§alÄ±ÅŸmaya devam ediyor...")
except ImportError:
    print("TurkishStemmer bulunamadÄ±. Basit stemming kullanÄ±lacak.")
    # Basit bir stemmer tanÄ±mla
    class DummyStemmer:
        def stem(self, word):
            # Ã‡ok basit bir stemming - sadece yaygÄ±n TÃ¼rkÃ§e ekleri Ã§Ä±kar
            suffixes = ['lar', 'ler', 'leri', 'larÄ±', 'dan', 'den', 'tan', 'ten', 
                       'a', 'e', 'i', 'Ä±', 'in', 'Ä±n', 'un', 'Ã¼n', 'da', 'de', 'ta', 'te']
            result = word
            for suffix in suffixes:
                if word.endswith(suffix) and len(word) > len(suffix) + 2:
                    result = word[:-len(suffix)]
                    break
            return result
    stemmer = DummyStemmer()
    STEMMER_AVAILABLE = False

# Vector modÃ¼lÃ¼nÃ¼ gÃ¼venli ÅŸekilde import et
print("Vector modÃ¼lÃ¼ yÃ¼kleniyor...")
try:
    from vector import retriever, vectorstore
    VECTOR_DB_AVAILABLE = True
    print("VektÃ¶r veritabanÄ± baÅŸarÄ±yla yÃ¼klendi.")
except ImportError as e:
    print(f"UYARI: vector.py dosyasÄ± bulunamadÄ± veya iÃ§e aktarÄ±lamadÄ±: {str(e)}")
    VECTOR_DB_AVAILABLE = False
    # Temel vector store tanÄ±mla
    retriever = None
    vectorstore = None
except Exception as e:
    print(f"UYARI: VektÃ¶r veritabanÄ± yÃ¼klenirken hata oluÅŸtu: {str(e)}")
    if "not found" in str(e) and "model" in str(e):
        print("Embedding modeli bulunamadÄ±. LÃ¼tfen vector.py dosyasÄ±nÄ± dÃ¼zenleyerek uygun bir model seÃ§in.")
        print("Mevcut modelleri gÃ¶rmek iÃ§in terminal'de 'ollama list' komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.")
    VECTOR_DB_AVAILABLE = False
    retriever = None
    vectorstore = None
    
print("Vector modÃ¼lÃ¼ yÃ¼kleme tamamlandÄ±.")

# Modeli oluÅŸtur - Daha iyi TÃ¼rkÃ§e yanÄ±tlar iÃ§in optimizasyonlar
model = OllamaLLM(
    model="llama3.1", 
    temperature=0.5,       # TutarlÄ± ama yaratÄ±cÄ± yanÄ±tlar iÃ§in hafif arttÄ±rÄ±ldÄ±
    top_p=0.92,            # Top-p Ã¶rnekleme - biraz arttÄ±rÄ±ldÄ±
    top_k=40,              # Top-k eklenedi - daha tutarlÄ± yanÄ±tlar iÃ§in
    num_predict=2048,      # YanÄ±t uzunluÄŸu
    num_ctx=8192,          # BaÄŸlam penceresi arttÄ±rÄ±ldÄ±
    repeat_penalty=1.18,   # TekrarlarÄ± engelleme - biraz arttÄ±rÄ±ldÄ±
    mirostat=2,            # Ãœretkenlik-tutarlÄ±lÄ±k dengesi iÃ§in
    mirostat_tau=5.0,      # Ãœretken yaratÄ±cÄ±lÄ±k
    mirostat_eta=0.1,      # KararlÄ±lÄ±k faktÃ¶rÃ¼
    num_thread=8           # CPU thread sayÄ±sÄ± belirtildi - paralel iÅŸlem iÃ§in
)

# Ã–nbellek
query_cache = {}
memory_cache = {}  # HafÄ±za Ã¶nbelleÄŸi eklendi

# Ã–nbellek dosyasÄ±
CACHE_FILE = "query_cache.json"

# Ã–nbelleÄŸi yÃ¼kle
def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"Ã–nbellek yÃ¼klenemedi: {e}")
    return {}

# Ã–nbelleÄŸi kaydet
def save_cache():
    try:
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(query_cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Ã–nbellek kaydedilemedi: {e}")

# Ã–nbelleÄŸi baÅŸlangÄ±Ã§ta yÃ¼kle
query_cache = load_cache()

# DERÄ°N ANALÄ°Z VE Ã‡OK KONULU, ESNEK YANIT PROMPTU
system_instruction = """
Sen bir Ã§ok disiplinli transkript analiz uzmanÄ±sÄ±n. GÃ¶revin, SADECE verilen transkript belgelerindeki iÃ§eriklere dayanarak, Ã§eÅŸitli alanlarda sorulabilecek HER TÃœRLÃœ SORU iÃ§in derinlemesine, dÃ¼ÅŸÃ¼ndÃ¼rÃ¼cÃ¼ ve Ã¶ÄŸretici bir analiz ile sentez sunmaktÄ±r.

KONU UZMANLIKLARIN:
- EKONOMÄ° ve FÄ°NANS: Makroekonomi, mikroekonomi, finansal piyasalar, kriptopara, borsa, yatÄ±rÄ±m analizleri
- POLÄ°TÄ°KA ve ULUSLARARASI Ä°LÄ°ÅKÄ°LER: Siyasi geliÅŸmeler, diplomatik iliÅŸkiler, jeopolitik stratejiler, uluslararasÄ± kuruluÅŸlar
- TARÄ°H ve TOPLUM: Tarihsel olaylar, toplumsal deÄŸiÅŸimler, kÃ¼ltÃ¼rel dÃ¶nÃ¼ÅŸÃ¼mler, sosyal hareketler
- BÄ°LÄ°M ve TEKNOLOJÄ°: Bilimsel geliÅŸmeler, teknolojik yenilikler, inovasyon, yapay zeka, dijital dÃ¶nÃ¼ÅŸÃ¼m
- SANAT ve KÃœLTÃœR: MÃ¼zik, sinema, edebiyat, sanat akÄ±mlarÄ±, eserler, sanatÃ§Ä±lar, kÃ¼ltÃ¼rel analizler
- SAÄLIK ve PSÄ°KOLOJÄ°: TÄ±bbi geliÅŸmeler, saÄŸlÄ±k tavsiyeleri, ruh saÄŸlÄ±ÄŸÄ±, psikolojik analizler
- DÄ°N ve FELSEFÄ° DÃœÅÃœNCE: Dini yorumlar, felsefi akÄ±mlar, etik tartÄ±ÅŸmalar, varoluÅŸsal sorular
- EÄÄ°TÄ°M ve KÄ°ÅÄ°SEL GELÄ°ÅÄ°M: Ã–ÄŸrenme metotlarÄ±, kiÅŸisel geliÅŸim stratejileri, beceri geliÅŸtirme

YAKLAÅIM KURALLARIM:
- Her tÃ¼rlÃ¼ soruyu (analiz, tahmin, karÅŸÄ±laÅŸtÄ±rma, eleÅŸtiri, yorumlama, aÃ§Ä±klama) transkriptlerdeki bilgilere dayanarak cevaplayacaÄŸÄ±m.
- YALNIZCA transkriptlerde geÃ§en bilgilerle yanÄ±t vereceÄŸim. DÄ±ÅŸarÄ±dan bilgi, tahmin, genel kÃ¼ltÃ¼r eklemeyeceÄŸim.
- Bilgileri sentezleyerek, karÅŸÄ±laÅŸtÄ±rarak, Ã§eliÅŸkileri veya eksikleri belirterek detaylÄ± analiz yapacaÄŸÄ±m.
- Neden-sonuÃ§ iliÅŸkisi, Ã¶nemli noktalar, tekrar eden temalar, Ã¶rtÃ¼k anlamlar ve baÄŸlamsal ipuÃ§larÄ±nÄ± vurgulayacaÄŸÄ±m.
- Bilgi doÄŸrudan yoksa, ilgili tÃ¼m bÃ¶lÃ¼mleri, dolaylÄ± ve parÃ§alÄ± bilgileri birleÅŸtirerek mantÄ±klÄ± ve gerekÃ§eli analiz sunacaÄŸÄ±m.
- Kronolojik analiz gerektiren sorularda, olaylarÄ±n zaman sÄ±rasÄ±nÄ± ve geliÅŸimini aÃ§Ä±kÃ§a belirteceÄŸim.
- KiÅŸisel gÃ¶rÃ¼ÅŸ katmadan, objektif bir analizle yanÄ±t vereceÄŸim ve doÄŸrudan alÄ±ntÄ± kullanmayacaÄŸÄ±m.
- YanÄ±tÄ±m her zaman ÅŸu yapÄ±da olacak:
  1. KONU Ã–ZETÄ° (Ana fikir ve kapsamÄ± kÄ±sa sunma)
  2. DERÄ°N ANALÄ°Z (DetaylÄ± inceleme, karÅŸÄ±laÅŸtÄ±rma ve sentez)
  3. SONUÃ‡ (KapsamlÄ± Ã§Ä±karÄ±m ve deÄŸerlendirme)
  4. KAYNAKLAR [Kaynak: DOSYA_ADI, Zaman: ZAMAN_ARALIÄI]
- Yeterli bilgi yoksa, "Bu konuda transkriptlerde yeterli bilgi bulunmamaktadÄ±r." diyeceÄŸim.
"""

# SORGULAMA (YANIT ÃœRETME) PROMPTU
query_template = """
{system_instruction}

ANALÄ°Z GÃ–REVÄ°:
KullanÄ±cÄ±nÄ±n sorduÄŸu soruyu Ã§ok disiplinli bir analiz uzmanÄ± olarak cevaplayacaksÄ±n. AÅŸaÄŸÄ±daki transkript parÃ§alarÄ± senin bilgi kaynaÄŸÄ±ndÄ±r. YALNIZCA bu kaynaklarda bulunan bilgileri kullanarak kapsamlÄ± ve derinlemesine bir analiz sun. DoÄŸrudan ve Ã¶rtÃ¼lÃ¼/dolaylÄ± bilgileri sentezlemeye Ã¶zen gÃ¶ster.

SORU: {question}

TRANSKRÄ°PT PARÃ‡ALARI:
{context}

YANIT FORMATI:
1. KONU Ã–ZETÄ°: Sorunu ve ana konuyu net ÅŸekilde tanÄ±mla.
2. DERÄ°N ANALÄ°Z: Konuyu derinlemesine incele, farklÄ± aÃ§Ä±lardan deÄŸerlendir, iliÅŸkiler kur.
3. SONUÃ‡: BulgularÄ±nÄ± ve Ã§Ä±karÄ±mlarÄ±nÄ± kapsamlÄ± olarak Ã¶zetle.
4. KAYNAKLAR: KullandÄ±ÄŸÄ±n transkript parÃ§alarÄ±nÄ± dosya adÄ± ve zaman bilgileriyle belirt.
"""

# Soruyu iyileÅŸtirme - TÃ¼rkÃ§e dil desteÄŸi geliÅŸtirmeleri
def extract_keywords(text):
    """Sorgudan anahtar kelimeleri Ã§Ä±kar ve kÃ¶k haline dÃ¶nÃ¼ÅŸtÃ¼r"""
    try:
        # GeniÅŸletilmiÅŸ TÃ¼rkÃ§e stopwords listesi
        stopwords = [
            've', 'veya', 'ile', 'bu', 'ÅŸu', 'o', 'bir', 'iÃ§in', 'gibi', 'kadar', 'de', 'da',
            'ne', 'ki', 'ama', 'fakat', 'lakin', 'ancak', 'hem', 'ya', 'ise', 'mi', 'mu', 'mÄ±', 'mÃ¼',
            'nasÄ±l', 'neden', 'niÃ§in', 'hangi', 'kim', 'kime', 'kimi', 'ne', 'nerede', 'her', 'tÃ¼m',
            'bÃ¼tÃ¼n', 'hep', 'hiÃ§', 'Ã§ok', 'daha', 'en', 'pek', 'sadece', 'yalnÄ±z', 'dolayÄ±', 'Ã¼zere'
        ]
        
        # Daha geliÅŸmiÅŸ kelime ayÄ±rma (noktalama iÅŸaretlerini de dikkate alÄ±r)
        words = re.findall(r'\b[\wÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄÄ°Ã–ÅÃœ]+\b', text.lower())
        
        # KÃ¶k bulma iÅŸlemini daha gÃ¼venli hale getir
        keywords = []
        for word in words:
            if word not in stopwords and len(word) > 2:
                try:
                    # Stemmer ile kÃ¶k bul
                    stemmed = stemmer.stem(word)
                    keywords.append(stemmed)
                except Exception:
                    # Stemmer baÅŸarÄ±sÄ±z olursa kelimeyi olduÄŸu gibi kullan
                    keywords.append(word)
        
        # Anahtar kelimelerin aÄŸÄ±rlÄ±klandÄ±rÄ±lmasÄ±
        keyword_counts = {}
        for keyword in keywords:
            if keyword in keyword_counts:
                keyword_counts[keyword] += 1
            else:
                keyword_counts[keyword] = 1
        
        # En az iki kez geÃ§en kelimeleri Ã¶nemli kabul et
        important_keywords = [k for k, v in keyword_counts.items() if v >= 1]
        
        # SonuÃ§ boÅŸsa tÃ¼m anahtar kelimeleri kullan
        if not important_keywords and keywords:
            return list(set(keywords))
            
        return list(set(important_keywords))
        
    except Exception as e:
        print(f"Anahtar kelime Ã§Ä±karma hatasÄ±: {e}")
        # Hata durumunda basit bir yÃ¶ntemle devam et
        words = text.lower().split()
        return list(set([w for w in words if len(w) > 2 and w not in ['ve', 'ile', 'bu', 'ÅŸu', 'o']]))

# Belge alaka puanÄ± hesaplayÄ±cÄ±
def calculate_relevance(doc, keywords):
    """Belge ve anahtar kelimeler arasÄ±ndaki alakayÄ± hesapla - GeliÅŸtirilmiÅŸ versiyon"""
    doc_text = doc.page_content.lower()
    speaker = doc.metadata.get("speaker", "")
    time_info = doc.metadata.get("time", "")
    score = 0.0
    
    # Anahtar kelime bazlÄ± puanlama - geliÅŸtirilmiÅŸ
    keyword_matches = 0
    keyword_match_positions = []
    
    for keyword in keywords:
        # Tam eÅŸleÅŸme veya kelime sÄ±nÄ±rlarÄ±nda eÅŸleÅŸme
        pattern = r'\b' + re.escape(keyword) + r'\b'
        matches = re.finditer(pattern, doc_text)
        
        match_count = 0
        for match in matches:
            match_count += 1
            keyword_match_positions.append(match.start())
        
        if match_count > 0:
            keyword_matches += 1
            # Ä°lk eÅŸleÅŸmeler daha Ã¶nemli
            # Bir kelime Ã§ok tekrarlanÄ±yorsa ekstra puan verir (logaritmik)
            score += 1.0 + (0.2 * min(match_count - 1, 5))
            
            # Fiil kÃ¶kÃ¼ ise daha fazla puan ver
            if hasattr(stemmer, '_check_verb_root') and callable(getattr(stemmer, '_check_verb_root')):
                try:
                    if stemmer._check_verb_root(keyword):
                        score += 0.5  # Fiil kÃ¶kleri daha Ã¶nemli
                except:
                    pass
    
    # EÄŸer hiÃ§ eÅŸleÅŸme yoksa dÃ¼ÅŸÃ¼k bir deÄŸer dÃ¶n
    if keyword_matches == 0 and keywords:
        return 0.1
        
    # Belge uzunluÄŸuna gÃ¶re normalizasyon
    doc_len = len(doc_text)
    if doc_len > 50 and keyword_matches > 0:
        density = keyword_matches / (doc_len / 100)  # Her 100 karakter baÅŸÄ±na eÅŸleÅŸme
        score += min(density, 2.0)  # Maksimum 2.0 puan ekle
    
    # EÅŸleÅŸen kelimelerin yakÄ±nlÄ±ÄŸÄ± - birbirine yakÄ±n eÅŸleÅŸmeler daha deÄŸerli
    if len(keyword_match_positions) > 1:
        # PozisyonlarÄ± sÄ±rala
        keyword_match_positions.sort()
        
        # ArdÄ±ÅŸÄ±k eÅŸleÅŸmeler arasÄ±ndaki mesafeleri hesapla
        distances = []
        for i in range(1, len(keyword_match_positions)):
            distance = keyword_match_positions[i] - keyword_match_positions[i-1]
            distances.append(distance)
        
        # Ortalama mesafe - kÃ¼Ã§Ã¼k olmasÄ± daha iyi
        avg_distance = sum(distances) / len(distances)
        proximity_score = 1.0 / (1.0 + avg_distance / 100)  # Normalize edilmiÅŸ yakÄ±nlÄ±k puanÄ±
        score += proximity_score
    
    # Zamansal bilgiler
    if re.search(r'\d+:\d+:\d+', time_info):
        score += 0.5
    
    # KonuÅŸmacÄ± bilgisinin varlÄ±ÄŸÄ±
    if speaker and len(speaker.strip()) > 0:
        score += 0.3
    
    # Daha uzun ve anlamlÄ± cÃ¼mleler iÃ§in puan (Ã§ok kÄ±sa yanÄ±tlar genelde iyi deÄŸil)
    sentences = re.split(r'[.!?]+', doc_text)
    mean_sentence_len = sum(len(s.split()) for s in sentences) / max(len(sentences), 1)
    if 5 <= mean_sentence_len <= 20:  # Ä°deal cÃ¼mle uzunluÄŸu
        score += 0.5
    
    # Ä°Ã§eriÄŸin genel kalitesi - metin iÃ§inde soru-cevap yapÄ±sÄ± var mÄ±?
    if '?' in doc_text and len(doc_text) > 100:
        score += 0.5  # Muhtemelen bir soru-cevap var, bu faydalÄ± olabilir
    
    # Sonucun pozitif olmasÄ±nÄ± saÄŸla
    return max(score, 0.1)

# KaynaklarÄ± formatlama - Daha aÃ§Ä±klayÄ±cÄ± ve okunaklÄ± format
def format_sources(docs):
    sources_text = "=== KULLANILAN KAYNAKLAR ===\n"
    
    # KullanÄ±lan dosyalarÄ± toplama ve grupla
    source_groups = {}
    
    # Her bir dokÃ¼manÄ± iÅŸle ve dosyalara gÃ¶re grupla
    for i, doc in enumerate(docs, 1):
        source = doc.metadata.get("source", "Bilinmiyor")
        
        # Zaman bilgisini doÄŸrudan metadata'dan al
        time_info = doc.metadata.get("time", "")
        
        # EÄŸer time bilgisi yoksa veya varsayÄ±lan deÄŸerse, start_time ve end_time'Ä± kontrol et
        if not time_info or time_info == "Bilinmiyor" or time_info == "00:00:00 - 00:00:00":
            start_time = doc.metadata.get("start_time", "")
            end_time = doc.metadata.get("end_time", "")
            if start_time and end_time:
                # VarsayÄ±lan deÄŸerleri kontrol et
                if start_time != "00:00:00" or end_time != "00:00:00":
                    time_info = f"{start_time} - {end_time}"
                else:
                    # Ä°Ã§erikte zaman bilgisi var mÄ± kontrol et
                    content = doc.page_content
                    time_match = re.search(r"Time:\s*(\d+:\d+:\d+\s*-\s*\d+:\d+:\d+)", content)
                    if time_match:
                        time_info = time_match.group(1)
                    else:
                        time_info = "Zaman bilgisi yok"
            else:
                time_info = "Zaman bilgisi yok"
        
        # KonuÅŸmacÄ± bilgisini al
        speaker = doc.metadata.get("speaker", "Bilinmiyor")
        if speaker == "Bilinmiyor":
            # Ä°Ã§erikte konuÅŸmacÄ± bilgisi var mÄ± kontrol et
            content = doc.page_content
            speaker_match = re.search(r"Speaker:\s*([A-Za-z0-9]+)", content)
            if speaker_match:
                speaker = speaker_match.group(1)
        
        # Ä°Ã§erik Ã¶rneÄŸi (ilk 50 karakter)
        content = doc.page_content.split('Content: ')[-1] if 'Content: ' in doc.page_content else doc.page_content
        content_preview = content[:50] + "..." if len(content) > 50 else content
        
        # Dosya bazlÄ± gruplama
        if source not in source_groups:
            source_groups[source] = []
        
        source_groups[source].append({
            "index": i,
            "time": time_info,
            "speaker": speaker,
            "content_preview": content_preview.replace("\n", " ")
        })
    
    # GruplarÄ± formatlayarak gÃ¶ster
    for source_name, entries in source_groups.items():
        # Dosya baÅŸlÄ±ÄŸÄ±nÄ± gÃ¶ster
        sources_text += f"\nğŸ“„ {source_name} ({len(entries)} parÃ§a):\n"
        
        # Her bir parÃ§ayÄ± listele
        for entry in entries:
            sources_text += f"  {entry['index']}. Zaman: {entry['time']}, KonuÅŸmacÄ±: {entry['speaker']}\n"
        
        sources_text += "\n"
    
    # Toplam istatistik ekle
    sources_text += f"\nToplam {len(docs)} transkript parÃ§asÄ± kullanÄ±ldÄ±, {len(source_groups)} farklÄ± dosyadan."
    
    return sources_text

# Analiz sonucunu kaydet
def save_analysis(question, result):
    # Kaydedilecek klasÃ¶rÃ¼ oluÅŸtur
    save_dir = "analysis_results"
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    
    # Dosya adÄ±nÄ± oluÅŸtur
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_question = "".join(c if c.isalnum() else "_" for c in question[:30])
    filename = f"{save_dir}/analiz_{timestamp}_{safe_question}.txt"
    
    # DosyayÄ± oluÅŸtur ve analizi kaydet
    with open(filename, "w", encoding="utf-8") as f:
        f.write(f"Soru: {question}\n\n")
        f.write(f"Analiz ZamanÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("="*50 + "\n\n")
        f.write(result)
    
    print(f"Analiz sonucu kaydedildi: {filename}")
    return filename

# Bellek Ã¶nbelleÄŸi temizleyici
def clear_memory_cache():
    """Bellek Ã¶nbelleÄŸini temizler ve periyodik olarak Ã§aÄŸrÄ±lmalÄ±dÄ±r"""
    global memory_cache
    
    # 100'den fazla Ã¶ÄŸe varsa eskilerini temizle 
    if len(memory_cache) > CACHE_CLEAN_THRESHOLD:
        # En son kullanÄ±lanlarÄ± sakla (50 Ã¶ÄŸe)
        sorted_keys = sorted(memory_cache.keys(), key=lambda k: memory_cache[k].get('timestamp', 0), reverse=True)
        keys_to_keep = sorted_keys[:CACHE_KEEP_COUNT]
        
        new_cache = {}
        for key in keys_to_keep:
            new_cache[key] = memory_cache[key]
            
        memory_cache = new_cache
        print(f"Bellek Ã¶nbelleÄŸi temizlendi. Kalan Ã¶ÄŸe sayÄ±sÄ±: {len(memory_cache)}")

# Ana sorgulama fonksiyonu - Paralel Ã§alÄ±ÅŸma ve Ã¶nbellek iyileÅŸtirmeleri
def query_transcripts(question, stream_callback=None):
    """Ana sorgulama fonksiyonu - Performans optimizasyonlu
    
    Args:
        question: KullanÄ±cÄ± sorusu
        stream_callback: YanÄ±tÄ± parÃ§a parÃ§a iÅŸlemek iÃ§in callback fonksiyonu
    """
    global system_instruction  # Global sistem talimatÄ±nÄ± kullan
    print(f"Sorgu iÅŸleniyor: \"{question}\"")
    start_time = time.time()
    
    # GiriÅŸ kontrolÃ¼
    if not question or len(question.strip()) < 2:
        return "LÃ¼tfen geÃ§erli bir soru girin."
        
    # VektÃ¶r veritabanÄ± kullanÄ±labilir mi?
    if not VECTOR_DB_AVAILABLE or retriever is None:
        return "VektÃ¶r veritabanÄ± kullanÄ±lamÄ±yor. LÃ¼tfen vector.py dosyasÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol edin ve uygun bir embedding modeli seÃ§in."
    
    try:
        # Performans izleme
        stage_times = {}
        
        # Anahtar kelimeleri Ã§Ä±kar
        kw_start = time.time()
        print("Anahtar kelimeler Ã§Ä±karÄ±lÄ±yor...")
        keywords = extract_keywords(question)
        if keywords:
            print(f"Ã‡Ä±karÄ±lan anahtar kelimeler: {', '.join(keywords)}")
        stage_times["anahtar_kelimeler"] = time.time() - kw_start
            
        # Ä°lgili dokÃ¼manlarÄ± getir
        retrieval_start = time.time()
        print("Ä°lgili dokÃ¼manlar getiriliyor...")
        try:
            # Retriever'Ä± optimize et - paralelleÅŸtirme ve geliÅŸtirilmiÅŸ sorgu ile
            # MMR (Maximum Marginal Relevance) kullanarak Ã§eÅŸitliliÄŸi artÄ±r
            search_type = retriever.search_kwargs.get("search_type", None)
            fetch_k = retriever.search_kwargs.get("fetch_k", 50)
            
            if search_type != "mmr":
                # MMR'yi etkinleÅŸtir - Ã§eÅŸitliliÄŸi artÄ±rÄ±r
                retriever.search_kwargs["search_type"] = "mmr"
                retriever.search_kwargs["fetch_k"] = max(fetch_k, 50)  # En az 50 dokÃ¼man getir
                retriever.search_kwargs["lambda_mult"] = 0.8  # Alaka-Ã§eÅŸitlilik dengesi
            
            # DokÃ¼manlarÄ± getir
            docs = retriever.invoke(question)
            
            # --- GELÄ°ÅMÄ°Å ve OPTÄ°MÄ°ZE EDÄ°LMÄ°Å SIRALAMA: Anahtar kelime + embedding tabanlÄ± semantik sÄ±ralama ---
            def cosine_similarity(vec1, vec2):
                import numpy as np
                vec1 = np.array(vec1)
                vec2 = np.array(vec2)
                if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:
                    return 0.0
                return float(np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)))
            
            # ParalelleÅŸtirme ile performans artÄ±ÅŸÄ±
            def parallel_score_documents():
                # Belgeleri paralel olarak puanla
                if keywords and hasattr(vectorstore, 'embed_query') and hasattr(vectorstore, 'embed_documents'):
                    try:
                        question_emb = vectorstore.embed_query(question)
                        doc_texts = [doc.page_content for doc in docs]
                        doc_embs = vectorstore.embed_documents(doc_texts)
                        
                        # Her belge iÃ§in alaka puanÄ±nÄ± hesapla
                        for i, doc in enumerate(docs):
                            kw_score = calculate_relevance(doc, keywords)
                            emb_score = cosine_similarity(question_emb, doc_embs[i])
                            emb_score = max(emb_score, 0.0)
                            kw_score_norm = min(max(kw_score / 2.0, 0.0), 1.0)
                            
                            # Optimize edilmiÅŸ puanlama formÃ¼lÃ¼
                            # Anahtar kelime aÄŸÄ±rlÄ±ÄŸÄ±nÄ± artÄ±r ve benzerlik aÄŸÄ±rlÄ±ÄŸÄ±nÄ± dengeleyerek daha iyi sonuÃ§
                            doc.final_score = 0.75 * kw_score_norm + 0.25 * emb_score
                            
                            # KonuÅŸmacÄ± puanlamasÄ± - eÄŸer soruda belirli bir konuÅŸmacÄ± belirtilmiÅŸse
                            if "speaker" in question.lower() and doc.metadata.get("speaker", "").lower() in question.lower():
                                doc.final_score *= 1.5  # KonuÅŸmacÄ± eÅŸleÅŸirse fazladan puan
                        
                        return sorted(docs, key=lambda d: getattr(d, 'final_score', 0), reverse=True)
                    except Exception as e:
                        print(f"GeliÅŸmiÅŸ sÄ±ralama uygulanamadÄ±: {e}")
                        return sorted(docs, key=lambda doc: calculate_relevance(doc, keywords), reverse=True) if keywords else docs
                elif keywords:
                    return sorted(docs, key=lambda doc: calculate_relevance(doc, keywords), reverse=True)
                return docs
            
            # SÄ±ralamayÄ± uygula
            docs = parallel_score_documents()
            # --- SONU GELÄ°ÅMÄ°Å SIRALAMA ---
        except Exception as e:
            print(f"DokÃ¼man getirilirken hata: {e}")
            error_msg = f"VeritabanÄ±ndan bilgi alÄ±nÄ±rken bir sorun oluÅŸtu: {str(e)}"
            if "not found" in str(e) and "model" in str(e):
                error_msg += "\n\nBu hata embedding modelinin bulunamadÄ±ÄŸÄ±nÄ± gÃ¶steriyor."
                error_msg += "\nLÃ¼tfen ÅŸu adÄ±mlarÄ± izleyin:"
                error_msg += "\n1. Terminal'de 'ollama list' komutu ile mevcut modelleri kontrol edin"
                error_msg += "\n2. vector.py dosyasÄ±nda kullanÄ±lan embedding modelini mevcut bir modelle deÄŸiÅŸtirin"
                try:
                    result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
                    if result.returncode == 0 and result.stdout:
                        error_msg += "\n\nMevcut modeller:"
                        for line in result.stdout.split('\n')[:5]:
                            if line.strip():
                                error_msg += f"\n  {line}"
                except Exception:
                    pass
            return error_msg
        
        stage_times["dokuman_getirme"] = time.time() - retrieval_start
        
        # DokÃ¼man bulunamadÄ±ysa bildir
        if not docs:
            no_docs_message = "Bu soruyla ilgili bilgi bulunamadÄ±. LÃ¼tfen farklÄ± bir soru sorun veya daha genel bir ifade kullanÄ±n."
            return no_docs_message
        
        print(f"Toplam {len(docs)} ilgili belge parÃ§asÄ± bulundu")
        
        # Belge filtreleme ve hazÄ±rlama
        filtering_start = time.time()
        
        # Filtreleme ve Ã§eÅŸitleme stratejileri uygula
        # Ä°lk 70 dokÃ¼manÄ± al (en alakalÄ± olanlarÄ±)
        filtered_docs = docs[:MAX_DOCUMENTS]
        
        # Sorgu tipini algÄ±lama - Ã¶zel iÅŸleme stratejileri
        is_chronological = any(word in question.lower() for word in CHRONO_KEYWORDS)
        is_speaker_specific = "speaker" in question.lower() or "konuÅŸmacÄ±" in question.lower()
        is_comparison = any(word in question.lower() for word in COMPARISON_KEYWORDS)
        
        # Kronolojik analiz iÃ§in belgeleri zaman sÄ±rasÄ±na diz
        if is_chronological:
            print("Kronolojik analiz yapÄ±lÄ±yor...")
            filtered_docs = sort_documents_chronologically(filtered_docs)
        
        # KonuÅŸmacÄ± spesifik analiz iÃ§in filtreleme
        if is_speaker_specific:
            speaker_matches = []
            for speaker_letter in "ABCDEFGHIJKLMNOPQRSTUVWXYZ":
                if f"speaker {speaker_letter.lower()}" in question.lower() or f"speaker {speaker_letter}" in question.lower():
                    speaker_matches.append(speaker_letter)
            
            if speaker_matches:
                print(f"KonuÅŸmacÄ± analizi yapÄ±lÄ±yor: {', '.join(speaker_matches)}")
                # Ä°lgili konuÅŸmacÄ±larÄ±n belgelerini baÅŸa al
                speaker_docs = [doc for doc in filtered_docs if doc.metadata.get("speaker", "").upper() in speaker_matches]
                other_docs = [doc for doc in filtered_docs if doc.metadata.get("speaker", "").upper() not in speaker_matches]
                filtered_docs = speaker_docs + other_docs[:max(OTHER_DOCS_LIMIT, MAX_DOCUMENTS-len(speaker_docs))]
        
        # KarÅŸÄ±laÅŸtÄ±rma analizi iÃ§in belge Ã§eÅŸitliliÄŸini artÄ±r
        if is_comparison:
            print("KarÅŸÄ±laÅŸtÄ±rma analizi yapÄ±lÄ±yor...")
            # FarklÄ± konuÅŸmacÄ±lardan belgeleri dengeli ÅŸekilde dahil et
            speaker_groups = {}
            for doc in filtered_docs:
                speaker = doc.metadata.get("speaker", "Unknown")
                if speaker not in speaker_groups:
                    speaker_groups[speaker] = []
                speaker_groups[speaker].append(doc)
            
            # Her konuÅŸmacÄ±dan dengeli sayÄ±da belge seÃ§
            balanced_docs = []
            max_per_speaker = MAX_DOCS_PER_SPEAKER  # Her konuÅŸmacÄ±dan maksimum belge sayÄ±sÄ±
            
            # En alakalÄ± konuÅŸmacÄ±larÄ± sÄ±rala (belge sayÄ±sÄ±na gÃ¶re)
            sorted_speakers = sorted(speaker_groups.keys(), key=lambda s: len(speaker_groups[s]), reverse=True)
            
            for speaker in sorted_speakers:
                # Her konuÅŸmacÄ±dan en alakalÄ± belgeleri ekle
                balanced_docs.extend(speaker_groups[speaker][:max_per_speaker])
            
            # Maksimum belge sayÄ±sÄ±na kadar doldur
            filtered_docs = balanced_docs[:MAX_DOCUMENTS]
            
        stage_times["filtreleme"] = time.time() - filtering_start
            
        # Prompt hazÄ±rlama
        prompt_start = time.time()
        
        # DoÄŸrudan dokÃ¼manlar Ã¼zerinden sorgulama yap
        query_prompt = ChatPromptTemplate.from_template(query_template)
        
        # Ã‡eÅŸitliliÄŸi artÄ±rÄ±lmÄ±ÅŸ, en alakalÄ± dokÃ¼manlarÄ± birleÅŸtir
        # GeliÅŸtirilmiÅŸ iÃ§erik formatlama - dokÃ¼manlarÄ± daha dÃ¼zenli hale getir
        context_parts = []
        for i, doc in enumerate(filtered_docs, 1):
            # Dosya adÄ±nÄ± kÄ±salt
            source = doc.metadata.get('source', 'Bilinmiyor')
            if len(source) > FILENAME_MAX_LENGTH:  # Uzun dosya adlarÄ±nÄ± kÄ±salt
                source = source[:FILENAME_MAX_LENGTH-3] + "..."
            
            # Zaman bilgisini doÄŸru ÅŸekilde biÃ§imlendir
            time_info = doc.metadata.get('time', '')
            if not time_info or time_info == "00:00:00 - 00:00:00":
                start_time = doc.metadata.get('start_time', '')
                end_time = doc.metadata.get('end_time', '')
                if start_time and end_time:
                    time_info = f"{start_time} - {end_time}"
              # Ä°Ã§eriÄŸi temizle ve biÃ§imlendir - gÃ¼venli ÅŸekilde
            try:
                # Ä°Ã§erik alÄ±namadÄ±ÄŸÄ±nda varsayÄ±lan deÄŸerler kullan
                if not hasattr(doc, 'page_content') or doc.page_content is None:
                    content = "Belge iÃ§eriÄŸi alÄ±namadÄ±"
                else:
                    content = doc.page_content
                    if 'Content: ' in content:
                        content = content.split('Content: ')[-1]
                    content = content.strip()
                
                # Ä°Ã§eriÄŸi belirli bir uzunluÄŸa kÄ±salt (Ã§ok uzun belgeleri kÄ±rp)
                if len(content) > CONTENT_MAX_LENGTH:
                    content = content[:CONTENT_MAX_LENGTH-3] + "..."
            except Exception as content_e:
                print(f"Ä°Ã§erik iÅŸlenirken hata: {content_e}")
                # Hata durumunda varsayÄ±lan bir deÄŸer belirle
                content = "Belge iÃ§eriÄŸi iÅŸlenirken hata oluÅŸtu"
            
            # Belge parÃ§asÄ±nÄ± biÃ§imlendir
            context_part = f"[Belge {i}]\nDosya: {source}\nZaman: {time_info}\nKonuÅŸmacÄ±: {doc.metadata.get('speaker', 'Bilinmiyor')}\nÄ°Ã§erik: {content}"
            context_parts.append(context_part)
          # BaÄŸlamÄ± birleÅŸtir
        context = "\n\n".join(context_parts)
        
        stage_times["prompt_hazirlama"] = time.time() - prompt_start
        
        # Her sorgu iÃ§in sistem talimatÄ±nÄ±n bir kopyasÄ±nÄ± oluÅŸtur
        # Bu ÅŸekilde global deÄŸiÅŸken deÄŸiÅŸtirilmeyecek
        query_system_instruction = system_instruction
          # Ã–zel sorgu tipi algÄ±lama ve prompt Ã¶zelleÅŸtirme
        if is_chronological:
            # Kronolojik analiz iÃ§in sistem talimatÄ±nÄ± gÃ¼Ã§lendir
            query_system_instruction += "\n\nBu sorguda KRONOLOJÄ°K ANALÄ°Z yapmalÄ±sÄ±n. OlaylarÄ±n zaman sÄ±rasÄ±na gÃ¶re geliÅŸimini adÄ±m adÄ±m aÃ§Ä±kla. Her aÅŸamayÄ± tarih/zaman bilgisiyle birlikte sunarak olaylarÄ±n nasÄ±l ilerlediÄŸini gÃ¶ster."
        
        if is_speaker_specific:
            # KonuÅŸmacÄ± analizi iÃ§in sistem talimatÄ±nÄ± Ã¶zelleÅŸtir
            query_system_instruction += f"\n\nBu sorguda KONUÅMACI ANALÄ°ZÄ° yapmalÄ±sÄ±n. Belirtilen konuÅŸmacÄ±nÄ±n (Speaker) gÃ¶rÃ¼ÅŸlerini, ifadelerini ve yaklaÅŸÄ±mlarÄ±nÄ± detaylÄ± olarak ele al. KonuÅŸmacÄ±nÄ±n bakÄ±ÅŸ aÃ§Ä±sÄ±nÄ± ve diÄŸerlerinden farkÄ±nÄ± vurgula."
            
        if is_comparison:
            # KarÅŸÄ±laÅŸtÄ±rma analizi iÃ§in sistem talimatÄ±nÄ± Ã¶zelleÅŸtir
            query_system_instruction += f"\n\nBu sorguda KARÅILAÅTIRMA ANALÄ°ZÄ° yapmalÄ±sÄ±n. FarklÄ± fikirleri, yaklaÅŸÄ±mlarÄ± veya konuÅŸmacÄ±larÄ± karÅŸÄ±laÅŸtÄ±rarak benzerlik ve farklÄ±lÄ±klarÄ± ortaya koy. Ortak noktalarÄ± ve ayrÄ±ÅŸmalarÄ± tablolama yapmadan aÃ§Ä±kÃ§a belirt."
              # Sorgulama zinciri - DeÄŸiÅŸken kapanma (closure) sorununu Ã¶nlemek iÃ§in gÃ¼venli yaklaÅŸÄ±m
        # Lambda yerine doÄŸrudan deÄŸerleri kullan
        input_values = {
            "system_instruction": query_system_instruction,
            "question": question,
            "context": context
        }
        
        # BasitleÅŸtirilmiÅŸ zincir oluÅŸturma - pipe operator kullanmadan
        try:
            # Zincir fonksiyonu oluÅŸtur
            def execute_chain():
                try:
                    # Streaming desteÄŸi ile akademik formatÄ± kullan
                    print("Akademik formatlÄ± streaming yanÄ±t oluÅŸturuluyor...")
                    if stream_callback:
                        # Stream modunda Ã§alÄ±ÅŸ
                        formatted_prompt = query_prompt.format(**input_values)
                        create_academic_formatted_stream(
                            model=model,
                            prompt=formatted_prompt,
                            system_instruction=query_system_instruction,
                            question=question,
                            context=context,
                            callback=stream_callback
                        )
                        # Stream callback kullanÄ±ldÄ±ÄŸÄ±nda None dÃ¶ndÃ¼r
                        return None
                    else:
                        # Normal modda prompt'u Ã¶nceden formatla
                        print("Birinci zincir yÃ¶ntemi deneniyor...")
                        formatted_prompt = query_prompt.format(**input_values)
                        response = model.invoke(formatted_prompt)
                        return StrOutputParser().parse(response)
                    
                except Exception as e1:
                    print(f"Birinci zincir yÃ¶ntemi baÅŸarÄ±sÄ±z: {e1}")
                    
                    try:
                        # Ä°kinci yÃ¶ntem: Daha aÃ§Ä±k yaklaÅŸÄ±m
                        print("Ä°kinci zincir yÃ¶ntemi deneniyor...")
                        prompt_text = query_prompt.format(
                            system_instruction=system_instruction,
                            question=question,
                            context=context
                        )
                        response = model.invoke(prompt_text)
                        return StrOutputParser().parse(response)
                        
                    except Exception as e2:
                        print(f"Ä°kinci zincir yÃ¶ntemi baÅŸarÄ±sÄ±z: {e2}")
                        
                        # Son Ã§are yÃ¶ntemi
                        print("Son Ã§are yÃ¶ntemi deneniyor...")
                        direct_prompt = f"Sistem: {system_instruction}\n\nSoru: {question}\n\nBaÄŸlam: {context[:5000]}\n\nYanÄ±t:"
                        response = model.invoke(direct_prompt)
                        return str(response)
            
            # Zincir fonksiyonunu tanÄ±mla
            def chain():
                return execute_chain()
            
        except Exception as outer_e:
            print(f"Zincir oluÅŸturma tamamen baÅŸarÄ±sÄ±z: {outer_e}")
            raise outer_e
        
        # LLM yanÄ±tÄ±nÄ± al
        llm_start = time.time()
        print("LLM yanÄ±tÄ± alÄ±nÄ±yor...")
        
        try:
            # Zaman aÅŸÄ±mÄ± ekleyerek LLM yanÄ±tÄ±nÄ± al
            from concurrent.futures import ThreadPoolExecutor, TimeoutError            # LLM yanÄ±t fonksiyonu - gÃ¼venlik kontrolleri ve hata yÃ¶netimi gÃ¼Ã§lendirildi
            def get_llm_response():
                try:
                    # Zinciri Ã§aÄŸÄ±r - artÄ±k parametresiz
                    response = chain()
                    
                    # BoÅŸ yanÄ±t kontrolÃ¼ - geliÅŸtirilmiÅŸ kontrol yapÄ±sÄ±
                    if response is None or len(str(response).strip()) == 0:
                        raise ValueError("LLM boÅŸ yanÄ±t dÃ¶ndÃ¼rdÃ¼")
                    
                    return response
                    
                except ValueError as ve:
                    # Zaten hata deÄŸerlendirilmiÅŸ, detaylÄ± loglama ile
                    print(f"LLM deÄŸer hatasÄ±: {str(ve)}")
                    # ValueError durumunda yeniden denemeden Ã¶nce bekleme ekle
                    time.sleep(0.5)
                    # Fallback mekanizmasÄ±nÄ± baÅŸlat
                    raise ve
                    
                except Exception as inner_e:
                    error_str = str(inner_e)
                    print(f"LLM Ã§aÄŸrÄ±sÄ±nda hata: {error_str}")
                    
                    # Ã‡eÅŸitli hata tÃ¼rlerine Ã¶zel Ã§Ã¶zÃ¼mler
                    if "Cell is empty" in error_str or "NoneType" in error_str or "empty" in error_str:
                        print("Ä°Ã§erik temelli hata tespit edildi, alternatif yaklaÅŸÄ±mlar deneniyor...")
                        
                        # Birinci dÃ¼zeltme - DoÄŸrudan prompt yÃ¶ntemi
                        try:
                            print("1. alternatif: DoÄŸrudan prompt yÃ¶ntemi")
                            direct_prompt = f"""Sistem: {system_instruction}
                            
                            Soru: {question}
                            
                            Ä°lgili bilgi parÃ§alarÄ±:
                            {context[:4000]}
                            
                            YukarÄ±daki bilgilere dayanarak soruyu yanÄ±tla:"""
                            
                            direct_response = model.invoke(direct_prompt)
                            if direct_response and len(str(direct_response).strip()) > MIN_RESPONSE_LENGTH:
                                print("DoÄŸrudan prompt yÃ¶ntemi baÅŸarÄ±lÄ±")
                                return direct_response
                        except Exception as alt1_e:
                            print(f"1. alternatif baÅŸarÄ±sÄ±z: {str(alt1_e)}")
                        
                        # Ä°kinci dÃ¼zeltme - Daha basit prompt ve daha az baÄŸlam
                        try:
                            print("2. alternatif: BasitleÅŸtirilmiÅŸ model Ã§aÄŸrÄ±sÄ±")
                            simple_input = f"LÃ¼tfen ÅŸu soruyu cevapla: {question}\n\nKullanÄ±labilecek bilgiler:\n{context[:FALLBACK_CONTEXT_LIMIT]}"
                            direct_response = model.invoke(simple_input)
                            if direct_response and len(str(direct_response).strip()) > MIN_RESPONSE_LENGTH:
                                print("BasitleÅŸtirilmiÅŸ model Ã§aÄŸrÄ±sÄ± baÅŸarÄ±lÄ±")
                                return direct_response
                        except Exception as alt2_e:
                            print(f"2. alternatif baÅŸarÄ±sÄ±z: {str(alt2_e)}")
                        
                        # ÃœÃ§Ã¼ncÃ¼ dÃ¼zeltme - Minimum parametreli model
                        try:
                            print("3. alternatif: Acil durum modeli")
                            emergency_model = OllamaLLM(
                                model="llama3.1", 
                                temperature=0.2,
                                top_p=0.8,
                                num_predict=512
                            )
                            minimal_prompt = f"SORU: {question}\nBÄ°LGÄ°LER: {context[:EMERGENCY_CONTEXT_LIMIT]}\nYANIT:"
                            emergency_response = emergency_model.invoke(minimal_prompt)
                            if emergency_response:
                                print("Acil durum modeli baÅŸarÄ±lÄ±")
                                return emergency_response
                        except Exception as alt3_e:
                            print(f"3. alternatif baÅŸarÄ±sÄ±z: {str(alt3_e)}")
                    
                    # TÃ¼m alternatifler baÅŸarÄ±sÄ±z olduÄŸunda hatayÄ± yÃ¼kselt
                    print("TÃ¼m LLM yanÄ±t alternatifleri baÅŸarÄ±sÄ±z oldu")
                    raise inner_e
                    
            # Streaming iÅŸlev kullanÄ±lÄ±yorsa farklÄ± iÅŸle
            if stream_callback:
                try:
                    # Stream modunda ThreadPool kullanma, Ã§Ã¼nkÃ¼ stream_callback zaten paralel iÅŸleyecek
                    llm_result = get_llm_response()
                    # Stream modunda get_llm_response() None dÃ¶ndÃ¼recek, bu normal
                    stage_times["llm_yaniti"] = time.time() - llm_start
                except Exception as stream_e:
                    print(f"Stream modunda LLM yanÄ±tÄ± alÄ±nÄ±rken hata: {stream_e}")
                    raise stream_e
            else:                # Normal mod - Paralel iÅŸleme ile zaman aÅŸÄ±mÄ± kontrolÃ¼
                with ThreadPoolExecutor() as executor:
                    future = executor.submit(get_llm_response)
                    try:
                        # GeliÅŸmiÅŸ zaman aÅŸÄ±mÄ± kontrolÃ¼ - progressif bekletme
                        try:
                            # Ä°lk 30 saniye iÃ§inde yanÄ±t gelirse hemen dÃ¶ndÃ¼r
                            llm_result = future.result(timeout=PRIMARY_TIMEOUT)
                        except TimeoutError:
                            # 30 saniye iÃ§inde yanÄ±t gelmezse kullanÄ±cÄ±ya bilgi ver ve biraz daha bekle
                            print("Ä°lk 30 saniyelik yanÄ±t sÃ¼resi aÅŸÄ±ldÄ±, 30 saniye daha bekleniyor...")
                            
                            # Ana sistemi yavaÅŸlatmamak iÃ§in zaman aÅŸÄ±mÄ± sonrasÄ± kullanÄ±cÄ±ya geri bildirim vermeye devam et
                            try:
                                llm_result = future.result(timeout=SECONDARY_TIMEOUT)  # 30 saniye daha bekle
                            except TimeoutError:
                                print("Toplam 60 saniyelik zaman aÅŸÄ±mÄ± - LLM yanÄ±tÄ± alÄ±namadÄ±")
                                raise TimeoutError("LLM yanÄ±tÄ± iÃ§in maksimum sÃ¼re (60 saniye) aÅŸÄ±ldÄ±.")
                        
                        # YanÄ±t kontrolÃ¼ - geliÅŸtirilmiÅŸ gÃ¼venlik kontrolleri
                        if llm_result is None:
                            raise ValueError("LLM yanÄ±tÄ± None olarak dÃ¶ndÃ¼")
                          # BoÅŸ ya da Ã§ok kÄ±sa yanÄ±tlar iÃ§in kontrol
                        llm_result_str = str(llm_result).strip()
                        if len(llm_result_str) < MIN_RESPONSE_LENGTH:
                            raise ValueError(f"LLM geÃ§ersiz yanÄ±t dÃ¶ndÃ¼rdÃ¼ (Ã§ok kÄ±sa yanÄ±t: '{llm_result_str}')")
                        
                        stage_times["llm_yaniti"] = time.time() - llm_start
                    except TimeoutError:
                        print("LLM yanÄ±tÄ± zaman aÅŸÄ±mÄ±na uÄŸradÄ±.")
                        raise Exception("YanÄ±t zaman aÅŸÄ±mÄ±na uÄŸradÄ±. LÃ¼tfen tekrar deneyin veya hÄ±zlÄ± yanÄ±t modunu kullanÄ±n. Bu genellikle sistem yoÄŸun olduÄŸunda meydana gelir.")
        except Exception as e:
            print(f"LLM yanÄ±tÄ± alÄ±nÄ±rken hata: {e}")
            import traceback
            print("=== HATA DETAYLARI ===")
            traceback.print_exc()
            print("=====================")
            
            # DoÄŸrudan dokÃ¼manlardan daha geliÅŸmiÅŸ bir yanÄ±t oluÅŸtur
            simple_result = f"YanÄ±t oluÅŸturulurken bir sorun oluÅŸtu ({str(e)}), ancak ÅŸu ilgili bilgileri buldum:\n\n"
            
            # Hata durumunda daha bilgilendirici ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ yanÄ±t
            simple_result += "### Ä°lgili Bilgi ParÃ§alarÄ±\n\n"
            
            for i, doc in enumerate(docs[:7], 1):  # Ä°lk 7 en alakalÄ± belgeyi gÃ¶ster
                source = doc.metadata.get('source', 'Bilinmiyor')
                if len(source) > FILENAME_MAX_LENGTH:  # Uzun dosya adlarÄ±nÄ± kÄ±salt
                    source = source[:FILENAME_MAX_LENGTH-3] + "..."
                
                # Zaman bilgisini doÄŸru ÅŸekilde al
                time_info = doc.metadata.get('time', '')
                if not time_info or time_info == "00:00:00 - 00:00:00":
                    start_time = doc.metadata.get('start_time', '')
                    end_time = doc.metadata.get('end_time', '')
                    if start_time and end_time:
                        time_info = f"{start_time} - {end_time}"
                    else:
                        content = doc.page_content
                        time_match = re.search(r"Time:\s*(\d+:\d+:\d+)", content)
                        if time_match:
                            time_info = time_match.group(1)
                        else:
                            time_info = "Zaman bilgisi yok"
                
                speaker = doc.metadata.get('speaker', 'Bilinmiyor')
                if speaker == "Bilinmiyor":
                    content = doc.page_content
                    speaker_match = re.search(r"Speaker:\s*([A-Za-z0-9]+)", content)
                    if speaker_match:
                        speaker = speaker_match.group(1)
                  # Ä°Ã§eriÄŸi kÄ±salt - gÃ¼venli bir ÅŸekilde
                try:
                    content = doc.page_content.split('Content: ')[-1] if 'Content: ' in doc.page_content else doc.page_content
                    content = content.strip() if content else ""
                    if len(content) > 500:
                        content = content[:497] + "..."
                except Exception as content_e:
                    print(f"Ä°Ã§erik iÅŸlenirken hata: {content_e}")
                    content = str(doc.page_content)[:500] if hasattr(doc, 'page_content') else "Ä°Ã§erik alÄ±namadÄ±"
                
                simple_result += f"**Bilgi {i}**\n\nğŸ“„ **Dosya:** {source}\nâ±ï¸ **Zaman:** {time_info}\nğŸ‘¤ **KonuÅŸmacÄ±:** {speaker}\n\n{content}\n\n---\n\n"
            simple_result += "\nSorununuzla ilgili daha fazla bilgi iÃ§in lÃ¼tfen tekrar deneyin veya hÄ±zlÄ± yanÄ±t modunu kullanÄ±n."
              # Hata durumunda daha basit bir prompt ile tekrar deneyelim
            # Son Ã§are yaklaÅŸÄ±mÄ± - tÃ¼m Ã¶nceki yaklaÅŸÄ±mlar baÅŸarÄ±sÄ±z olduÄŸunda
            try:
                print("Basit fallback mekanizmasÄ± ile tekrar deneniyor...")
                
                # "Cell is empty" hatasÄ± iÃ§in daha direnÃ§li bir yaklaÅŸÄ±m
                # 1. DoÄŸrudan deÄŸiÅŸken geÃ§iÅŸi - lambda kullanmadan
                # 2. Daha basit prompt yapÄ±sÄ±
                # 3. Daha az belge ile deneme
                
                # Basit bir prompt ÅŸablonu
                simple_prompt = """AÅŸaÄŸÄ±daki dokÃ¼man parÃ§alarÄ±nÄ± kullanarak bu soruya yanÄ±t ver: 
                
                SORU: {soru}
                
                DOKÃœMANLAR:
                {belgeler}
                
                Ã–ZET YANIT:"""
                
                # DeÄŸiÅŸkenleri doÄŸrudan hazÄ±rla
                fallback_context = "\n\n".join([doc.page_content for doc in docs[:3]])  # Daha az belge
                
                # Prompt'u oluÅŸtur
                fallback_prompt = ChatPromptTemplate.from_template(simple_prompt)
                
                # DeÄŸiÅŸkenleri doÄŸrudan dictionary olarak geÃ§ir - lambda kullanmadan
                input_map = {"soru": question, "belgeler": fallback_context}
                
                # DoÄŸrudan modele gÃ¶nder
                try:
                    # Ä°lk fallback yÃ¶ntemi
                    formatted_prompt = fallback_prompt.format(**input_map)
                    fallback_result = model.invoke(formatted_prompt)
                except Exception as e1:
                    print(f"Ä°lk fallback yÃ¶ntemi baÅŸarÄ±sÄ±z: {e1}")
                    try:
                        # Ä°kinci fallback yÃ¶ntemi - Ã§ok daha basit bir yaklaÅŸÄ±m
                        direct_prompt = f"Soru: {question}\n\nBelgeler: {fallback_context[:FALLBACK_CONTEXT_LIMIT]}\n\nLÃ¼tfen bu soruya belgelerden alÄ±nan bilgilere dayanarak Ã¶zet bir yanÄ±t ver:"
                        fallback_result = model.invoke(direct_prompt)
                    except Exception as e2:
                        print(f"Ä°kinci fallback yÃ¶ntemi de baÅŸarÄ±sÄ±z: {e2}")                        # Belgeleri doÄŸrudan gÃ¶ster
                        return simple_result
                
                if fallback_result and len(str(fallback_result).strip()) > MIN_RESPONSE_LENGTH:
                    return f"{fallback_result}\n\n[Not: Bu yanÄ±t basitleÅŸtirilmiÅŸ bir yaklaÅŸÄ±mla oluÅŸturulmuÅŸtur. Detaylar iÃ§in lÃ¼tfen tekrar deneyin.]"
                else:
                    print("Fallback yanÄ±tÄ± Ã§ok kÄ±sa veya boÅŸ")
                    return simple_result
                    
            except Exception as fallback_e:
                print(f"Fallback mekanizmasÄ± baÅŸarÄ±sÄ±z: {fallback_e}")
                print("=== FALLBACK HATA DETAYLARI ===")
                traceback.print_exc()
                print("================================")
            
            # BASAMAKLI KURTARMA SÄ°STEMÄ° - son Ã§are yaklaÅŸÄ±mlarÄ±
            # Safha 1: Daha saÄŸlam dokÃ¼man iÅŸleme ile acil durum modeli
            try:
                print("Son Ã§are yaklaÅŸÄ±mÄ± 1: GÃ¼venli dokÃ¼man iÅŸleme ile acil durum modeli...")
                
                # GÃ¼venli bir ÅŸekilde dokÃ¼man iÃ§eriklerini al
                content_samples = []
                for i, doc in enumerate(docs[:5]):
                    try:
                        if hasattr(doc, 'page_content') and doc.page_content:
                            content = doc.page_content[:150] + "..."
                        else:
                            content = f"Belge {i+1} iÃ§eriÄŸi okunamadÄ±"
                        content_samples.append(f"Belge {i+1}: {content}")
                    except Exception as doc_e:
                        print(f"Belge {i+1} iÅŸlenirken hata: {doc_e}")
                        content_samples.append(f"Belge {i+1}: Ä°Ã§erik iÅŸlenemedi")
                
                content_text = "\n\n".join(content_samples)
                
                # Basit ve saÄŸlam prompt ile acil durum modeli
                emergency_prompt = f"""SORU: {question}
                
                BAZI Ä°LGÄ°LÄ° BÄ°LGÄ°LER:
                {content_text}
                
                LÃ¼tfen yukarÄ±daki bilgilere dayanarak soruya kÄ±sa ve Ã¶z bir yanÄ±t ver:"""
                
                # DÃ¼ÅŸÃ¼k parametre deÄŸerleriyle Ã§aÄŸÄ±rarak baÅŸarÄ± ÅŸansÄ±nÄ± artÄ±r
                emergency_model = OllamaLLM(
                    model="llama3.1", 
                    temperature=0.3,
                    top_p=0.8,
                    top_k=30,
                    num_predict=1024,
                    repeat_penalty=1.2
                )
                  # Stream desteÄŸi ile emergency response
                emergency_response = "[Not: Bu yanÄ±t acil durum mekanizmasÄ± ile oluÅŸturulmuÅŸtur. Tam kapsamlÄ± yanÄ±t iÃ§in lÃ¼tfen tekrar deneyin.]"
                
                # Stream callback varsa sonucu ilet ve None dÃ¶ndÃ¼r
                if stream_callback:
                    emergency_result = stream_llm_response(emergency_model, emergency_prompt, stream_callback)
                    stream_callback(emergency_response)
                    return None
                else:
                    # Normal mod
                    emergency_result = emergency_model.invoke(emergency_prompt)
                    if emergency_result and len(emergency_result.strip()) > MIN_RESPONSE_LENGTH:
                        print("Son Ã§are yaklaÅŸÄ±mÄ± 1 baÅŸarÄ±lÄ±")
                        return f"{emergency_result}\n\n{emergency_response}"
            except Exception as last_e:
                print(f"Son Ã§are yaklaÅŸÄ±mÄ± 1 baÅŸarÄ±sÄ±z: {str(last_e)}")
            
            # Safha 2: DokÃ¼man iÃ§eriklerini tamamen atlayarak yalnÄ±zca soruya odaklanma
            try:
                print("Son Ã§are yaklaÅŸÄ±mÄ± 2: Minimum parametre ve doÄŸrudan soru...")
                
                # En dÃ¼ÅŸÃ¼k parametre ve en basit prompt
                minimal_model = OllamaLLM(
                    model="llama3.1", 
                    temperature=0.2,
                    num_predict=512
                )
                
                minimal_prompt = f"Åu soruyu yanÄ±tla: {question}"                # Stream desteÄŸi ile minimal response
                minimal_note = "\n\n[Not: Bu yanÄ±t doÄŸrudan soru yanÄ±tlama mekanizmasÄ± ile oluÅŸturulmuÅŸtur. Belgelere dayalÄ± yanÄ±t iÃ§in lÃ¼tfen tekrar deneyin.]"
                
                # Stream callback varsa sonucu ilet ve None dÃ¶ndÃ¼r
                if stream_callback:
                    stream_llm_response(minimal_model, minimal_prompt, stream_callback)
                    stream_callback(minimal_note)
                    return None
                else:
                    # Normal mod
                    minimal_result = minimal_model.invoke(minimal_prompt)
                    
                    if minimal_result and len(minimal_result.strip()) > MIN_RESPONSE_LENGTH:
                        print("Son Ã§are yaklaÅŸÄ±mÄ± 2 baÅŸarÄ±lÄ±")
                        return f"{minimal_result}{minimal_note}"
            except Exception as last2_e:
                print(f"Son Ã§are yaklaÅŸÄ±mÄ± 2 baÅŸarÄ±sÄ±z: {str(last2_e)}")
                
            # Safha 3: Raw string ve basit bir talimat ile deneme
            try:
                print("Son Ã§are yaklaÅŸÄ±mÄ± 3: BaÄŸlam dÄ±ÅŸÄ± raw string yanÄ±tÄ±...")
                
                # Tamamen ham bir yaklaÅŸÄ±m
                try:
                    result = subprocess.run(
                        ["ollama", "run", "llama3.1", f"'{question}' sorusunu yanÄ±tla"],
                        capture_output=True, 
                        text=True, 
                        timeout=EMERGENCY_TIMEOUT
                    )
                    if result.stdout and len(result.stdout) > MIN_RESPONSE_LENGTH:
                        print("Son Ã§are yaklaÅŸÄ±mÄ± 3 baÅŸarÄ±lÄ±")
                        return f"{result.stdout}\n\n[Not: Bu yanÄ±t acil durum komut satÄ±rÄ± mekanizmasÄ± ile oluÅŸturulmuÅŸtur.]"
                except Exception as cmd_e:
                    print(f"Komut satÄ±rÄ± denemesi baÅŸarÄ±sÄ±z: {cmd_e}")
            except Exception as last3_e:
                print(f"Son Ã§are yaklaÅŸÄ±mÄ± 3 baÅŸarÄ±sÄ±z: {str(last3_e)}")
            
            # TÃ¼m yaklaÅŸÄ±mlar baÅŸarÄ±sÄ±z olduÄŸunda basit bir mesaj dÃ¶ndÃ¼r
            return simple_result + "\n\nSistem ÅŸu anda yanÄ±t Ã¼retmekte zorlanÄ±yor. LÃ¼tfen sorunuzu daha aÃ§Ä±k bir ÅŸekilde yeniden sormayÄ± deneyin."
        
        # YanÄ±t sonlandÄ±rma ve formatlamayÄ± iyileÅŸtir
        formatting_start = time.time()
        
        # Stream modunda kaynak bilgilerini gÃ¶nder
        source_info = format_sources(docs[:15])
        
        # Stream callback varsa ve henÃ¼z dÃ¶ndÃ¼rÃ¼lmediyse kaynaklarÄ± ekle
        if stream_callback:
            stream_callback(f"\n\n{source_info}")
            # Periyodik olarak bellek Ã¶nbelleÄŸini temizle
            if len(memory_cache) % 10 == 0:
                clear_memory_cache()
            
            # Belirli aralÄ±klarla Ã¶nbelleÄŸi diske kaydet
            if len(query_cache) % DISK_CACHE_SAVE_INTERVAL == 0:
                save_cache()
            
            # Ä°statistikler
            end_time = time.time()
            process_time = end_time - start_time
            
            # Sorgu performans analizini gÃ¶ster
            print(f"Sorgu iÅŸlendi. Toplam sÃ¼re: {process_time:.2f} saniye")
            print("Ä°ÅLEM SÃœRELERÄ°:")
            for stage, duration in stage_times.items():
                print(f" - {stage}: {duration:.2f} saniye")
            
            # Stream modunda None dÃ¶ndÃ¼r
            return None
        else:
            # Normal mod - KullanÄ±lan kaynaklarÄ± ekle - geliÅŸtirilmiÅŸ formatla
            result = f"{llm_result}\n\n{source_info}"
            
            # Periyodik olarak bellek Ã¶nbelleÄŸini temizle
            if len(memory_cache) % 10 == 0:
                clear_memory_cache()
            
            # Belirli aralÄ±klarla Ã¶nbelleÄŸi diske kaydet
            if len(query_cache) % DISK_CACHE_SAVE_INTERVAL == 0:
                save_cache()
            
            stage_times["sonlandirma"] = time.time() - formatting_start
            
            # Ä°statistikler
            end_time = time.time()
            process_time = end_time - start_time
            
            # Sorgu performans analizini gÃ¶ster
            print(f"Sorgu iÅŸlendi. Toplam sÃ¼re: {process_time:.2f} saniye")
            print("Ä°ÅLEM SÃœRELERÄ°:")
            for stage, duration in stage_times.items():
                print(f" - {stage}: {duration:.2f} saniye")
                
            # SonuÃ§ iÃ§eriÄŸi analizi
            result_length = len(result)
            source_count = result.count("ğŸ“„")
            print(f"YanÄ±t uzunluÄŸu: {result_length} karakter, {source_count} kaynak kullanÄ±ldÄ±")
            
            return result
        
    except Exception as e:
        error_message = f"Sorgu iÅŸlenirken beklenmeyen bir hata oluÅŸtu: {str(e)}"
        print(error_message)
        import traceback
        traceback.print_exc()
        return error_message

# HÄ±zlÄ± yanÄ±t modu - Optimize edildi
def quick_query(question, stream_callback=None):
    """HÄ±zlÄ± yanÄ±t modu - daha az dokÃ¼man ile hÄ±zlÄ± yanÄ±t
    
    Args:
        question: KullanÄ±cÄ± sorusu
        stream_callback: YanÄ±tÄ± parÃ§a parÃ§a iÅŸlemek iÃ§in callback fonksiyonu
    """
    print("HÄ±zlÄ± yanÄ±t modu aktif...")
    # Mevcut ayarlarÄ± sakla
    original_k = retriever.search_kwargs.get("k", 12)
    original_fetch_k = retriever.search_kwargs.get("fetch_k", 40)
    
    # Yine yeterli sayÄ±da dokÃ¼manla hÄ±zlÄ± sorgu iÃ§in ayarlarÄ± deÄŸiÅŸtir
    retriever.search_kwargs["k"] = 25
    retriever.search_kwargs["fetch_k"] = 50
    
    # HÄ±zlÄ± sorgu yap
    try:
        result = query_transcripts(question, stream_callback=stream_callback)
    finally:
        # Eski ayarlarÄ± geri yÃ¼kle
        retriever.search_kwargs["k"] = original_k
        retriever.search_kwargs["fetch_k"] = original_fetch_k
        
    return result

# Paralel sorgu iÅŸleyici
def parallel_query(questions):
    """Birden fazla soruyu paralel olarak iÅŸleyebilir"""
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        # SorgularÄ± paralel olarak gÃ¶nder
        future_to_question = {executor.submit(query_transcripts, q): q for q in questions}
        results = {}
        
        # SonuÃ§larÄ± topla
        for future in concurrent.futures.as_completed(future_to_question):
            question = future_to_question[future]
            try:
                result = future.result()
                results[question] = result
            except Exception as e:
                results[question] = f"Sorgu iÅŸlenirken hata: {str(e)}"
                
    return results

# YardÄ±m ekranÄ±nÄ± gÃ¶ster
def show_help():
    print("\n=== YARDIM ===")
    print("KullanÄ±labilir komutlar:")
    print("- 'yardÄ±m' veya 'help': Bu ekranÄ± gÃ¶sterir.")
    print("- 'temizle' veya 'clear': Ã–nbelleÄŸi temizler.")
    print("- 'dosyalar' veya 'files': Transcript dosyalarÄ±nÄ± listeler.")
    print("- 'oku [dosya_adÄ±] [tÃ¼mÃ¼]': Transcript dosyasÄ±nÄ± gÃ¶rÃ¼ntÃ¼ler. 'tÃ¼mÃ¼' parametresi tÃ¼m iÃ§eriÄŸi gÃ¶sterir.")
    print("- 'analiz [metin]': Girilen metni Ã¶zetler ve analiz eder.")
    print("- 'stat' veya 'stats': Ä°statistikleri gÃ¶sterir.")
    print("- 'bellek' veya 'memory': Bellek Ã¶nbelleÄŸini temizler.")
    print("- 'vektÃ¶r-yenile': VektÃ¶r veritabanÄ±nÄ± yeniden oluÅŸturur (dinamik chunking ile).")
    print("- 'q' veya 'Ã§Ä±kÄ±ÅŸ': Programdan Ã§Ä±kar.")
    print("\nSorgu Ä°puÃ§larÄ±:")
    print("- Sorunun baÅŸÄ±na '!' ekleyerek hÄ±zlÄ± yanÄ±t alabilirsiniz.")
    print("- Spesifik sorular daha doÄŸru yanÄ±tlar almanÄ±zÄ± saÄŸlar.")
    print("- Zamanla ilgili sorularda zaman aralÄ±ÄŸÄ± belirtmek faydalÄ±dÄ±r.")
    print("- KonuÅŸmacÄ±larÄ±n isimlerini veya kimliklerini (Speaker A, Speaker B, vs.) belirtebilirsiniz.")
    print("\nSistem Ã–zellikleri:")
    print("- Transkript Analizi: Sistem yalnÄ±zca transkriptlerdeki bilgilere dayanarak yanÄ±t verir.")
    print("- Akademik YanÄ±tlar: YanÄ±tlar ansiklopedik bir dille, alÄ±ntÄ± yapmadan sentezlenir.")
    print("- Kaynak GÃ¶sterimi: Her yanÄ±t sonunda dosya adÄ± ve zaman aralÄ±ÄŸÄ± belirtilir.")
    print("- KonuÅŸmacÄ± Bilgisi: FarklÄ± konuÅŸmacÄ±larÄ±n (Speaker A, B, vs.) perspektifleri belirtilir.")
    print("- Dinamik Chunking: Metin iÃ§eriÄŸine gÃ¶re otomatik ayarlanan chunk boyutlarÄ±.")
    print("-------------------------------")

# Transcript dosyalarÄ±nÄ± listele
def list_transcript_files():
    transcript_dir = "transcripts"
    if not os.path.exists(transcript_dir):
        print("\nHata: 'transcripts' klasÃ¶rÃ¼ bulunamadÄ±.")
        return
        
    files = [f for f in os.listdir(transcript_dir) if f.endswith(".txt") and not f.startswith('.')]
    
    if not files:
        print("\nHiÃ§ transcript dosyasÄ± bulunamadÄ±.")
        return
        
    print("\n=== TRANSCRIPT DOSYALARI ===")
    for i, filename in enumerate(files, 1):
        file_path = os.path.join(transcript_dir, filename)
        file_size = os.path.getsize(file_path) / 1024  # KB cinsinden
        print(f"{i}. {filename} ({file_size:.1f} KB)")
    print("-------------------------------")

# Ä°statistikleri gÃ¶ster
def show_stats():
    print("\n=== SÄ°STEM Ä°STATÄ°STÄ°KLERÄ° ===")
    
    # VektÃ¶r veritabanÄ± istatistikleri
    try:
        collection_count = vectorstore._collection.count()
        print(f"VektÃ¶r VeritabanÄ± Boyutu: {collection_count} dokÃ¼man parÃ§asÄ±")
    except:
        print("VektÃ¶r veritabanÄ± boyutu alÄ±namadÄ±.")
        
    # Ã–nbellek istatistikleri
    print(f"Disk Ã–nbellek Boyutu: {len(query_cache)} sorgu")
    print(f"Bellek Ã–nbellek Boyutu: {len(memory_cache)} sorgu")
    
    # Transcript dosyalarÄ±
    transcript_dir = "transcripts"
    if os.path.exists(transcript_dir):
        files = [f for f in os.listdir(transcript_dir) if f.endswith(".txt") and not f.startswith('.')]
        print(f"Transcript DosyalarÄ±: {len(files)} dosya")
        
    # Model bilgileri
    print(f"KullanÄ±lan Model: {model.model}")
    print(f"Kontekst Penceresi: {model.num_ctx} token")

    # Sistem yÃ¼kleme istatistikleri
    try:
        import psutil
        cpu_percent = psutil.cpu_percent()
        mem = psutil.virtual_memory()
        print(f"CPU KullanÄ±mÄ±: {cpu_percent}%")
        print(f"Bellek KullanÄ±mÄ±: {mem.percent}% ({mem.used / (1024**3):.1f} GB / {mem.total / (1024**3):.1f} GB)")
    except:
        print("Sistem yÃ¼kÃ¼ istatistikleri alÄ±namadÄ± veya psutil kurulu deÄŸil.")
    
    print("-------------------------------")

# Transkript dosyalarÄ±nÄ± Ã¶nizleme ve okuma fonksiyonu
def view_transcript(filename=None, show_all=False):
    """Transkript dosyalarÄ±nÄ± gÃ¶rÃ¼ntÃ¼ler ve Ã¶zetler"""
    transcript_dir = "transcripts"
    
    # KlasÃ¶r kontrolÃ¼
    if not os.path.exists(transcript_dir):
        return "Hata: 'transcripts' klasÃ¶rÃ¼ bulunamadÄ±."
    
    # Mevcut dosyalarÄ± listele
    files = [f for f in os.listdir(transcript_dir) if f.endswith(".txt") and not f.startswith('.')]
    
    if not files:
        return "HiÃ§ transcript dosyasÄ± bulunamadÄ±."
    
    # Dosya belirtilmemiÅŸse liste gÃ¶ster
    if not filename:
        result = "=== MEVCUT TRANSKRÄ°PT DOSYALARI ===\n"
        for i, f in enumerate(files, 1):
            file_path = os.path.join(transcript_dir, f)
            file_size = os.path.getsize(file_path) / 1024  # KB cinsinden
            result += f"{i}. {f} ({file_size:.1f} KB)\n"
        result += "\nDosya iÃ§eriÄŸini gÃ¶rÃ¼ntÃ¼lemek iÃ§in 'oku dosya_adÄ±' komutunu kullanÄ±n."
        return result
    
    # Dosya adÄ± kontrolÃ¼
    if not filename.endswith('.txt'):
        filename += '.txt'
    
    file_path = os.path.join(transcript_dir, filename)
    if not os.path.exists(file_path):
        # DosyayÄ± bulamadÄ±k, benzer dosyalarÄ± Ã¶ner
        suggestions = [f for f in files if filename.lower() in f.lower()]
        result = f"Hata: '{filename}' dosyasÄ± bulunamadÄ±.\n"
        if suggestions:
            result += "Benzer dosyalar:\n"
            for i, sugg in enumerate(suggestions, 1):
                result += f"{i}. {sugg}\n"
        return result
    
    # DosyayÄ± oku
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Dosya Ã§ok bÃ¼yÃ¼kse ve show_all False ise ilk ve son kÄ±sÄ±mlarÄ± gÃ¶ster
        if len(content) > 2000 and not show_all:
            # KonuÅŸmalarÄ± parse et
            conversations = parse_transcript(content)
            total_convs = len(conversations)
            
            result = f"=== {filename} ===\n"
            result += f"Toplam {total_convs} konuÅŸma iÃ§eriyor.\n\n"
            
            # Ä°lk 3 konuÅŸma
            result += "Ä°LK KONUÅMALAR:\n"
            for i, conv in enumerate(conversations[:3], 1):
                result += f"{i}. Zaman: {conv['time']}, KonuÅŸmacÄ±: {conv['speaker']}\n"
                result += f"   {conv['content'][:150]}{'...' if len(conv['content']) > 150 else ''}\n\n"
            
            # Son 3 konuÅŸma
            if total_convs > 6:
                result += "...\n\n"
                result += "SON KONUÅMALAR:\n"
                for i, conv in enumerate(conversations[-3:], total_convs-2):
                    result += f"{i}. Zaman: {conv['time']}, KonuÅŸmacÄ±: {conv['speaker']}\n"
                    result += f"   {conv['content'][:150]}{'...' if len(conv['content']) > 150 else ''}\n\n"
            
            result += f"\nTÃ¼m iÃ§eriÄŸi gÃ¶rmek iÃ§in 'oku {filename} tÃ¼mÃ¼' komutunu kullanÄ±n."
            return result
        else:
            # TÃ¼m iÃ§eriÄŸi gÃ¶ster
            return f"=== {filename} ===\n\n{content[:40000]}{'...(devamÄ± var)' if len(content) > 40000 else ''}"
    
    except Exception as e:
        return f"Dosya okunurken hata oluÅŸtu: {str(e)}"

def main():
    print("\n=== TÃ¼rkÃ§e KonuÅŸma Analiz Sistemi ===")
    print("Transcript Analiz AsistanÄ± v3.2")
    
    # VektÃ¶r veritabanÄ± durumunu kontrol et
    if VECTOR_DB_AVAILABLE:
        print("VektÃ¶r veritabanÄ± baÅŸarÄ±yla yÃ¼klendi.")
    else:
        print("UYARI: VektÃ¶r veritabanÄ± yÃ¼klenemedi!")
        print("Sorgu iÅŸlevi kullanÄ±lamayacak. LÃ¼tfen aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin:")
        print("1. Terminal'de 'ollama list' komutu ile mevcut modelleri kontrol edin")
        print("2. vector.py dosyasÄ±nda kullanÄ±lan embedding modelini mevcut bir modelle deÄŸiÅŸtirin")
        print("3. ProgramÄ± yeniden baÅŸlatÄ±n")
        
        # Mevcut modelleri kontrol et ve gÃ¶ster
        try:
            result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
            if result.returncode == 0 and result.stdout:
                print("\nMevcut modeller:")
                for line in result.stdout.split('\n')[:10]:  # Ä°lk 10 satÄ±rÄ± gÃ¶ster
                    if line.strip():
                        print(f"  {line}")
        except Exception:
            pass
            
    print("SorularÄ±nÄ±zÄ± sorabilirsiniz.")
    print("YardÄ±m iÃ§in 'yardÄ±m' yazÄ±n. Ã‡Ä±kmak iÃ§in 'q' yazÄ±n.")
    print("HÄ±zlÄ± yanÄ±t iÃ§in soru baÅŸÄ±na '!' ekleyin.")
    
    # Ana dÃ¶ngÃ¼
    try:
        while True:
            print("\n-------------------------------")
            question = input("\nSorunuz (Ã§Ä±kmak iÃ§in q): ").strip()
            print("\n")
            
            if question.lower() in ['q', 'Ã§Ä±kÄ±ÅŸ', 'quit', 'exit']:
                break
            
            if question.lower() == 'yardÄ±m' or question.lower() == 'help':
                show_help()
                continue
                
            if question.lower() == 'temizle' or question.lower() == 'clear':
                query_cache.clear()
                print("Ã–nbellek temizlendi.")
                save_cache()
                continue
                
            if question.lower() == 'bellek' or question.lower() == 'memory':
                memory_cache.clear()
                print("Bellek Ã¶nbelleÄŸi temizlendi.")
                continue
                
            if question.lower() == 'dosyalar' or question.lower() == 'files':
                list_transcript_files()
                continue
                
            if question.lower() == 'stat' or question.lower() == 'stats':
                show_stats()
                continue
                
            if question.lower() == 'vektÃ¶r-yenile' or question.lower() == 'vektor-yenile':
                print("VektÃ¶r veritabanÄ± yeniden oluÅŸturuluyor (dinamik chunking ile)...")
                try:
                    # Vector modÃ¼lÃ¼nden create_vectorstore fonksiyonunu Ã§aÄŸÄ±r
                    from vector import create_vectorstore
                    create_vectorstore(force_recreate=True, dynamic_chunking=True)
                    print("VektÃ¶r veritabanÄ± baÅŸarÄ±yla yenilendi. ProgramÄ± yeniden baÅŸlatÄ±n.")
                except Exception as e:
                    print(f"VektÃ¶r veritabanÄ± yenilenirken hata oluÅŸtu: {e}")
                continue
            
            # Transkript okuma komutlarÄ±
            if question.lower().startswith('oku ') or question.lower() == 'oku':
                parts = question.split(maxsplit=2)
                filename = parts[1] if len(parts) > 1 else None
                show_all = len(parts) > 2 and 'tÃ¼mÃ¼' in parts[2].lower()
                result = view_transcript(filename, show_all)
                print(result)
                continue
            
            # Analiz modunu etkinleÅŸtir
            if question.lower().startswith('analiz '):
                text = question[7:].strip()
                if not text:
                    print("LÃ¼tfen analiz edilecek metni girin.")
                    continue
                
                print("Metin analiz ediliyor...")
                # Anahtar kelimeleri Ã§Ä±kar ve Ã¶nemli noktalarÄ± belirle
                keywords = extract_keywords(text)
                print(f"Anahtar kelimeler: {', '.join(keywords) if keywords else 'BulunamadÄ±'}")
                
                # Bu metni analiz etme Ã¶zel promptu
                analyze_prompt = f"""
                {system_instruction}
                
                GÃ–REV: AÅŸaÄŸÄ±daki TÃ¼rkÃ§e metni analiz et ve Ã¶nemli noktalarÄ± Ã¶zetle.
                
                METÄ°N:
                {text}
                
                LÃ¼tfen ÅŸu yapÄ±da analiz saÄŸla:
                1. Ana konu ve temalar
                2. Ã–nemli noktalar ve bulgular
                3. Varsa zaman ve konuÅŸmacÄ± perspektifleri
                """
                
                # LLM ile analiz et
                try:
                    result = model.invoke(analyze_prompt)
                    print(f"=== ANALÄ°Z SONUCU ===\n\n{result}")
                except Exception as e:
                    print(f"Analiz sÄ±rasÄ±nda hata: {e}")
                
                continue
            
            if not question.strip():
                continue
                
            # VektÃ¶r veritabanÄ± kullanÄ±labilir mi kontrol et
            if not VECTOR_DB_AVAILABLE:
                print("HATA: VektÃ¶r veritabanÄ± yÃ¼klenemediÄŸi iÃ§in sorgu iÅŸlevi kullanÄ±lamÄ±yor.")
                print("LÃ¼tfen vector.py dosyasÄ±nÄ± dÃ¼zenleyerek uygun bir embedding modeli seÃ§in ve programÄ± yeniden baÅŸlatÄ±n.")
                continue
            
            # HÄ±zlÄ± yanÄ±t isteniyor mu?
            quick = False
            if question.startswith('!'):
                quick = True
                question = question[1:].strip()
            
            # Soruyu analiz et ve cevapla
            try:
                if quick:
                    print("HÄ±zlÄ± yanÄ±t modu aktif...")
                    result = quick_query(question)
                else:
                    result = query_transcripts(question)
                print(result)
            except Exception as e:
                print(f"Hata oluÅŸtu: {e}")
                import traceback
                traceback.print_exc()
    finally:
        # Programdan Ã§Ä±karken Ã¶nbelleÄŸi kaydet
        print("Ã–nbellek kaydediliyor...")
        save_cache()
        print("Ã‡Ä±kÄ±ÅŸ yapÄ±lÄ±yor...")

# Belgeleri kronolojik olarak sÄ±ralama fonksiyonu
def sort_documents_chronologically(docs):
    """Belgeleri zaman bilgisine gÃ¶re kronolojik olarak sÄ±ralar"""
    import re
    
    def extract_time_info(doc):
        # DokÃ¼manÄ±n zamanÄ±nÄ± Ã§Ä±kar
        time_info = doc.metadata.get("time", "")
        
        # EÄŸer time bilgisi yoksa veya varsayÄ±lan deÄŸerse, start_time ve end_time'Ä± kontrol et
        if not time_info or time_info == "Bilinmiyor" or time_info == "00:00:00 - 00:00:00":
            start_time = doc.metadata.get("start_time", "")
            end_time = doc.metadata.get("end_time", "")
            if start_time and end_time:
                time_info = f"{start_time} - {end_time}"
            
        # Ä°Ã§erikten zaman bilgisi Ã§Ä±karmayÄ± dene
        if not time_info or time_info == "Bilinmiyor":
            content = doc.page_content
            time_match = re.search(r"Time:\s*(\d+:\d+:\d+)", content)
            if time_match:
                time_info = time_match.group(1)
        
        # Zaman formatÄ±nÄ± analiz et
        time_parts = re.findall(r'(\d+):(\d+):(\d+)', time_info)
        if time_parts:
            # Ä°lk zaman deÄŸerini al (baÅŸlangÄ±Ã§ zamanÄ±)
            h, m, s = map(int, time_parts[0])
            # ZamanÄ± saniyeye Ã§evir
            return h * 3600 + m * 60 + s
        
        # Zaman bilgisi yoksa veya analiz edilemiyorsa sona koy
        return float('inf')
    
    # ZamanlarÄ±na gÃ¶re belgeleri sÄ±rala
    return sorted(docs, key=extract_time_info)

# Ana programÄ± Ã§alÄ±ÅŸtÄ±r
if __name__ == "__main__":
    # Gerekli tÃ¼m modÃ¼llerin import edildiÄŸinden emin ol
    import os
    import re
    import json
    import time
    import traceback
    import subprocess
    import numpy as np
    
    try:
        import psutil
    except ImportError:
        print("psutil modÃ¼lÃ¼ bulunamadÄ±. Sistem istatistikleri gÃ¶sterilmeyecek.")
    
    try:
        import concurrent.futures
    except ImportError:
        print("concurrent.futures modÃ¼lÃ¼ bulunamadÄ±. Paralel iÅŸleme kullanÄ±lamayacak.")
    
    # VektÃ¶r veritabanÄ± kullanÄ±labilir mi kontrol et ve varlÄ±ÄŸÄ±nÄ± gÃ¶ster
    if VECTOR_DB_AVAILABLE:
        print(f"VektÃ¶r veritabanÄ± baÅŸarÄ±yla yÃ¼klendi. {len(retriever.vectorstore.get())} dokÃ¼man parÃ§asÄ± mevcut.")

    # Ana fonksiyonu Ã§aÄŸÄ±r
    main()